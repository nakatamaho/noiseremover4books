{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Fetched 222 kB in 1s (186 kB/s)                                   \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Calculating upgrade... Done\n",
      "The following packages have been kept back:\n",
      "  libnvinfer-plugin7 libnvinfer7\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libgl1-mesa-dev is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libglib2.0-0 is already the newest version (2.64.6-1~ubuntu20.04.4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get upgrade -y\n",
    "!apt install -y libgl1-mesa-dev\n",
    "!apt install -y libglib2.0-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tqdm\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 17 07:45:41 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   32C    P8    17W / 340W |     17MiB / 10240MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import ImageFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 for GeForce RTX 3080 10GB\n",
    "#55 for V100 40GB\n",
    "images_per_batch = 14\n",
    "window_width = 256\n",
    "window_height = 256\n",
    "model_name=\"00/scannoise_remover_model\"\n",
    "era_name=\"00/scannoise_remover_era\"\n",
    "make_noised_images = \"no\"\n",
    "make_image_split = \"no\"\n",
    "noise_algorithm = \"new\"\n",
    "groundtruthdir=\"/work/groundtruth/\"\n",
    "cleanimagedir=\"/work/clean/\"\n",
    "noisedimagedir=\"/work/noised/\"\n",
    "epochs = 100\n",
    "eras = 100\n",
    "images_per_bulk = images_per_batch * 100\n",
    "validation_percent = 20\n",
    "restart_era = 0\n",
    "restart_epoch = 0\n",
    "testimages_max = 3000\n",
    "if restart_epoch != 0:\n",
    "    restart = \"yes\"\n",
    "else:\n",
    "    restart = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linenoise(filename, out_dirname):\n",
    "\n",
    "    sigma = 0.35\n",
    "    max_thickness = 20\n",
    "    min_thickness = 8\n",
    "    center_high = 24\n",
    "    center_low = 6\n",
    "\n",
    "    image_orig = cv2.imread(filename)\n",
    "    height, width, c = image_orig.shape\n",
    "    avarage_pixel = int (np.array(image_orig, dtype='float32').sum()/(height*width)/3.)\n",
    "\n",
    "    output_filename_woext = os.path.splitext(os.path.basename(filename))[0]\n",
    "    output_dir = os.path.split(os.path.dirname(filename))\n",
    "    os.makedirs(out_dirname +\"/\" + output_dir[-1], exist_ok=True)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        randline_img = image_orig.copy()\n",
    "        randline_img = np.array(randline_img, dtype='float32')\n",
    "        thickness=random.randint(1,max_thickness/2)*2+1\n",
    "        rand_x=random.randint(      thickness - int(thickness/2) - 1, width - int(thickness/2) - 1)\n",
    "        __col = random.randint(0,7)\n",
    "        _r = __col % 2\n",
    "        _g = (__col >> 1) % 2\n",
    "        _b = (__col >> 2) % 2\n",
    "        _flag = random.randrange(-1,2,2)\n",
    "        if avarage_pixel > 200 and _flag == 1:\n",
    "            _flag = -1\n",
    "        if avarage_pixel < 60 and _flag == -1:\n",
    "            _flag = 1\n",
    "        weight_center = random.randrange(center_low,center_high)/100.\n",
    "        variance_high = int(weight_center*100.)\n",
    "        variance_low = int(weight_center*100. * 0.85)\n",
    "        weight_width = variance_high/100.0 - random.randrange(variance_low,variance_high)/100.\n",
    "\n",
    "        for __x in range(thickness):\n",
    "            _x = __x - int(thickness/2)\n",
    "            distance_from_center = - (int(thickness/2) - abs(_x) ) / int(thickness/2) + 1\n",
    "            gauss_dist = math.exp ( - (distance_from_center) **2  / (2.0 * sigma **2 ) )\n",
    "            for _y in range(height):\n",
    "                _col = randline_img[_y, rand_x + _x]\n",
    "                weight = random.triangular(weight_center-weight_width, weight_center+weight_width, weight_center)\n",
    "                _col[0] = (_r * 255.) * gauss_dist * _flag * weight + _col [0]\n",
    "                _col[1] = (_g * 255.) * gauss_dist * _flag * weight + _col [1]\n",
    "                _col[2] = (_b * 255.) * gauss_dist * _flag * weight + _col [2]\n",
    "                if _col[0] > 255.:\n",
    "                    _col[0] = 255.\n",
    "                if _col[1] > 255.:\n",
    "                    _col[1] = 255.\n",
    "                if _col[2] > 255.:\n",
    "                    _col[2] = 255.\n",
    "                if _col[0] < 0.:\n",
    "                    _col[0] = 0.\n",
    "                if _col[1] < 0.:\n",
    "                    _col[1] = 0.\n",
    "                if _col[2] < 0.:\n",
    "                    _col[2] = 0.\n",
    "                randline_img[_y, rand_x + _x] = _col\n",
    "        randline_img = np.array(randline_img, dtype='int16')\n",
    "        orig_img = np.array(image_orig, dtype='int16')\n",
    "        randline_img_rgb = randline_img[:,:,0]+randline_img[:,:,1]+randline_img[:,:,2]\n",
    "        orig_img_rgb = orig_img[:,:,0]+orig_img[:,:,1]+orig_img[:,:,2]\n",
    "\n",
    "        diff = np.abs(randline_img_rgb - orig_img_rgb)\n",
    "        diff_max = diff.max()\n",
    "        diff_sum = diff.sum()\n",
    "        if diff_sum < 1200 or diff_max < 30:\n",
    "            counter = counter + 1\n",
    "            if counter > 10:\n",
    "                print(\"diff_max, diff_sum, _flag, weight_center, weight_width, thickness, average_pixel\",  output_filename_woext, diff_max, diff_sum, _flag, weight_center, weight_width, thickness, avarage_pixel)\n",
    "            continue\n",
    "        else:\n",
    "            #print(\"absmax, sum, _flag, weight_center, weight_width, thickness\",  output_filename_woext, diff_max, diff_sum, _flag,\n",
    "            #weight_center, weight_width, thickness, avarage_pixel)\n",
    "            #print(\"ok\")\n",
    "            randline_img = np.array(randline_img, dtype='uint8')\n",
    "            cv2.imwrite(out_dirname +\"/\" + output_dir[-1] + \"/\" + output_filename_woext+\".png\",randline_img)\n",
    "            return (filename, rand_x, _flag, weight_center, weight_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgSplit(filename, out_dirname):\n",
    "    height = window_height\n",
    "    width = window_width\n",
    "    \n",
    "    im = cv2.imread(filename)\n",
    "    output_filename_woext = os.path.splitext(os.path.basename(filename))[0]\n",
    "    output_dir = os.path.split(os.path.dirname(filename))\n",
    "    os.makedirs(out_dirname +\"/\" + output_dir[-1], exist_ok=True) \n",
    "    img_height, img_width = im.shape[:2]\n",
    "    # do not make a patch when image patch is too small\n",
    "    if (img_height < window_height) or (img_width < window_width):\n",
    "        return\n",
    "    split_height = int(img_height / height) \n",
    "    split_width = int(img_width / width)\n",
    "    for h1 in range(split_height+1):\n",
    "        for w1 in range(split_width+1):\n",
    "            w2 = w1 * width\n",
    "            h2 = h1 * height\n",
    "            _h_start = h2\n",
    "            _h_end   = height+h2-1\n",
    "            _w_start = w2\n",
    "            _w_end   = width+w2-1\n",
    "            if h1 == split_height:\n",
    "                _h_start = img_height-height\n",
    "                _h_end   = img_height-1\n",
    "            if w1 == split_width:\n",
    "                _w_start = img_width-width\n",
    "                _w_end   = img_width-1\n",
    "            c = im[_h_start:_h_end+1, _w_start:_w_end+1]\n",
    "            if (_h_end+1 - _h_start) == height and (_w_end+1 - _w_start) == width:\n",
    "                cv2.imwrite(out_dirname +\"/\" + output_dir[-1] + \"/\" + output_filename_woext + \"_\" + str(h1).zfill(3) + \"_\" + str(w1).zfill(3) +\".png\",c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do not make testimages\n"
     ]
    }
   ],
   "source": [
    "if make_image_split != \"no\":\n",
    "    print(\"making testimages\")\n",
    "    filenames_list=glob.glob(groundtruthdir + \"/*/*.jpg\")\n",
    "    try:\n",
    "        shutil.rmtree(cleanimagedir)\n",
    "    except OSError as e:\n",
    "        pass    \n",
    "    pathlib.Path(cleanimagedir).mkdir()\n",
    "    \n",
    "    for _filename in tqdm.tqdm(filenames_list):\n",
    "        ImgSplit(_filename, out_dirname = cleanimagedir)\n",
    "else:\n",
    "    print(\"do not make testimages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if make_noised_images != \"no\":\n",
    "    print(\"making noised images\")\n",
    "    try:\n",
    "        shutil.rmtree(noisedimagedir)       \n",
    "    except OSError as e:\n",
    "        pass\n",
    "    pathlib.Path(noisedimagedir).mkdir()\n",
    "    filenames_list=glob.glob(cleanimagedir + \"*/*.png\")\n",
    "    for _filename in tqdm.tqdm(filenames_list):\n",
    "        if noise_algorithm == \"old\":\n",
    "            #print(\"using old noise algorithm\")\n",
    "            pp = add_linenoise_old(_filename, out_dirname = noisedimagedir)\n",
    "        else:\n",
    "            #print(\"using new noise algorithm\")\n",
    "            pp = add_linenoise(_filename, out_dirname = noisedimagedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images 856074\n"
     ]
    }
   ],
   "source": [
    "filenames_train_list=sorted(glob.glob(noisedimagedir + \"*/*.png\"))\n",
    "filenames_target_list=sorted(glob.glob(cleanimagedir + \"*/*.png\"))\n",
    "counter_train = len(filenames_train_list)\n",
    "counter_target = len(filenames_target_list)\n",
    "if (counter_train != counter_target):\n",
    "    print(\"something wrong in num of pics of target and trains\")\n",
    "    exit(1)\n",
    "numof_train = int(counter_target * (100.0-validation_percent) / 100.0 )\n",
    "numof_validation = counter_target - numof_train\n",
    "print(\"total images\",counter_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if restart == \"yes\":\n",
    "    print(\"restarting from era, epoch #\", restart_era, restart_epoch)\n",
    "    era_pickle_file_current=era_name + '.' + str(restart_era).zfill(3) +'.current.pickle'\n",
    "    era_pickle_file_nextcal=era_name + '.' + str(restart_era).zfill(3) +'.nextcal.pickle'\n",
    "    with open(era_pickle_file_current, mode='rb') as f:\n",
    "        pickle.load(ERA_X, f)\n",
    "    with open(era_pickle_file_nextcal, mode='rb') as f:\n",
    "        pickle.load(ERA_X_next, f)\n",
    "else:\n",
    "    numof_total_files = len(filenames_train_list)\n",
    "    numof_1st_era_x= numof_total_files-int(counter_target * 0.01)\n",
    "    ERA_X, ERA_X_next= train_test_split(filenames_train_list, test_size=numof_1st_era_x, random_state=42) #from sklearn\n",
    "\n",
    "    era_pickle_file_current=era_name + '.' + str(0).zfill(3) +'.current.pickle'\n",
    "    era_pickle_file_nextcal=era_name + '.' + str(0).zfill(3) +'.nextcal.pickle'\n",
    "\n",
    "    with open(era_pickle_file_current, mode='wb') as f:\n",
    "        pickle.dump(ERA_X, f)\n",
    "    with open(era_pickle_file_nextcal, mode='wb') as f:\n",
    "        pickle.dump(ERA_X_next, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(_X_train, _Y_train, _images_per_batch):\n",
    "    print(\"getting a batch\")\n",
    "    print(\"images per batch\", _images_per_batch)\n",
    "    numof_batchs = len(_X_train)//_images_per_batch\n",
    "    print(\"Number of batches\", numof_batchs)\n",
    "\n",
    "    i = 0\n",
    "    while (i < numof_batchs):\n",
    "        print(\"doing a batch of \", i, \"/\", numof_batchs)\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        Y_batch = _Y_train[(i * _images_per_batch):(i * _images_per_batch + _images_per_batch)]\n",
    "        X_batch = _X_train[(i * _images_per_batch):(i * _images_per_batch + _images_per_batch)]\n",
    "        i += 1\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bulk(_X_train, _Y_train, _images_per_bulk):\n",
    "    print(\"images per bluk\", _images_per_bulk)\n",
    "    numof_bulks = len(_X_train)// _images_per_bulk\n",
    "    print(\"Number of bulks\", numof_bulks)\n",
    "    i = 0\n",
    "    while (i < numof_bulks):\n",
    "        print(\"doing a bulk of \", i, \"/\", numof_bulks)\n",
    "        X_train_bulk = []\n",
    "        Y_train_bulk = []\n",
    "        X_train_bulk_name = []\n",
    "        Y_train_bulk_name = []\n",
    "        print(\"getting a bluk...start \")\n",
    "        X_train_name = _X_train[(i * _images_per_bulk):(i * _images_per_bulk + _images_per_bulk)]\n",
    "        Y_train_name = _Y_train[(i * _images_per_bulk):(i * _images_per_bulk + _images_per_bulk)]\n",
    "        X_train_bulk = np.array([np.array(Image.open(file)) for file in X_train_name])\n",
    "        Y_train_bulk = np.array([np.array(Image.open(file)) for file in Y_train_name])\n",
    "        print(\"getting a bluk...done \")\n",
    "\n",
    "        i += 1\n",
    "        yield X_train_bulk, Y_train_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split noised data to training and test (validation) sets\n",
    "X_train, x_test= train_test_split(ERA_X, test_size=validation_percent, random_state=42) #from sklearn\n",
    "Y_train = [s.replace(noisedimagedir, cleanimagedir) for s in X_train]\n",
    "y_test = [s.replace(noisedimagedir, cleanimagedir) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(window_height, window_width, 3))\n",
    "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "for i in range(15):\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(3, (3, 3), padding='same')(x)\n",
    "output_img = Activation('tanh')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_img, output_img)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "0 / 0  ERAS\n",
      "==================================================\n",
      "0 / 100  EPOCHS\n",
      "images per bluk 1400\n",
      "Number of bulks 6\n",
      "doing a bulk of  0 / 6\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.6786\n",
      "batch accuracy: 0.6786156892776489\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6859\n",
      "batch accuracy: 0.6859493851661682\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5114\n",
      "batch accuracy: 0.5113998651504517\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8033\n",
      "batch accuracy: 0.8033280372619629\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5158\n",
      "batch accuracy: 1.5158127546310425\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.9550\n",
      "batch accuracy: 1.955016851425171\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.0243\n",
      "batch accuracy: 2.0243310928344727\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.1925\n",
      "batch accuracy: 2.1924736499786377\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.5676\n",
      "batch accuracy: 2.567565679550171\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.0098\n",
      "batch accuracy: 3.0098299980163574\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.2140\n",
      "batch accuracy: 3.2140023708343506\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.2376\n",
      "batch accuracy: 2.237633228302002\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.8276\n",
      "batch accuracy: 1.827638864517212\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.2088\n",
      "batch accuracy: 2.2087669372558594\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9518\n",
      "batch accuracy: 1.9518321752548218\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1509\n",
      "batch accuracy: 2.1508586406707764\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0990\n",
      "batch accuracy: 2.0989699363708496\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.1267\n",
      "batch accuracy: 1.1267002820968628\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.1822\n",
      "batch accuracy: 1.1821775436401367\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1492\n",
      "batch accuracy: 1.149237871170044\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1735\n",
      "batch accuracy: 1.173521876335144\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0356\n",
      "batch accuracy: 1.0355546474456787\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0878\n",
      "batch accuracy: 1.0878044366836548\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.2174\n",
      "batch accuracy: 1.2174394130706787\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0168\n",
      "batch accuracy: 1.0167644023895264\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9544\n",
      "batch accuracy: 0.954438328742981\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0367\n",
      "batch accuracy: 1.0366604328155518\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.7462\n",
      "batch accuracy: 1.7461974620819092\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7476\n",
      "batch accuracy: 1.7475539445877075\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9089\n",
      "batch accuracy: 1.9088627099990845\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1062\n",
      "batch accuracy: 2.1062095165252686\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.7655\n",
      "batch accuracy: 1.7655292749404907\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1437\n",
      "batch accuracy: 1.143722653388977\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.3262\n",
      "batch accuracy: 1.3261535167694092\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.5567\n",
      "batch accuracy: 1.5567235946655273\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4871\n",
      "batch accuracy: 1.4870898723602295\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.9297\n",
      "batch accuracy: 0.9296701550483704\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8093\n",
      "batch accuracy: 0.8093218207359314\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5818\n",
      "batch accuracy: 0.5818119049072266\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2796\n",
      "batch accuracy: 0.27961060404777527\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1776\n",
      "batch accuracy: 0.17760668694972992\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1149\n",
      "batch accuracy: 0.11491169780492783\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1109\n",
      "batch accuracy: 0.1108856201171875\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1431\n",
      "batch accuracy: 0.14308655261993408\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2036\n",
      "batch accuracy: 0.2035859376192093\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2169\n",
      "batch accuracy: 0.21686120331287384\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3528\n",
      "batch accuracy: 0.3528124988079071\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2493\n",
      "batch accuracy: 0.2492518424987793\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0685\n",
      "batch accuracy: 0.0685056820511818\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1373\n",
      "batch accuracy: 0.13726036250591278\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0455\n",
      "batch accuracy: 0.04546636343002319\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0325\n",
      "batch accuracy: 0.03247791528701782\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0661\n",
      "batch accuracy: 0.06612084805965424\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0360\n",
      "batch accuracy: 0.036042775958776474\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0466\n",
      "batch accuracy: 0.04662507027387619\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0272\n",
      "batch accuracy: 0.027233872562646866\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0313\n",
      "batch accuracy: 0.031269751489162445\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0437\n",
      "batch accuracy: 0.04368948936462402\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0200\n",
      "batch accuracy: 0.02000066079199314\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0212\n",
      "batch accuracy: 0.021202558651566505\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0250\n",
      "batch accuracy: 0.02502734586596489\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0325\n",
      "batch accuracy: 0.0325375460088253\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0341\n",
      "batch accuracy: 0.034110479056835175\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0610\n",
      "batch accuracy: 0.06099443882703781\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0375\n",
      "batch accuracy: 0.03754273056983948\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0348\n",
      "batch accuracy: 0.03482252359390259\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0685\n",
      "batch accuracy: 0.06845381110906601\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0501\n",
      "batch accuracy: 0.050112735480070114\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0359\n",
      "batch accuracy: 0.035916514694690704\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0352\n",
      "batch accuracy: 0.035164725035429\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0196\n",
      "batch accuracy: 0.019589055329561234\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0453\n",
      "batch accuracy: 0.04529167339205742\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0657\n",
      "batch accuracy: 0.06571599841117859\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0338\n",
      "batch accuracy: 0.033762458711862564\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0507\n",
      "batch accuracy: 0.05074906349182129\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0257\n",
      "batch accuracy: 0.02571004256606102\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0339\n",
      "batch accuracy: 0.03387096896767616\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0238\n",
      "batch accuracy: 0.023827945813536644\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0325\n",
      "batch accuracy: 0.032464709132909775\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m Y_batch \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_on_batch(X_batch, Y_batch)\n\u001b[0;32m---> 24\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, score)\n\u001b[1;32m     26\u001b[0m acc\u001b[38;5;241m.\u001b[39mappend(score)\u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2001\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     data_handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m     \u001b[38;5;66;03m# iteration.\u001b[39;00m\n\u001b[0;32m-> 2001\u001b[0m     data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2006\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2013\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py:1579\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py:1259\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1258\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1274\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py:347\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    345\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 347\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py:380\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices_dataset, inputs):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124;03m\"\"\"Slice inputs into a Dataset of batches.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    Given a Dataset of batch indices and the unsliced inputs,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m      A Dataset of input batches matching the batch indices.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip(\n\u001b[0;32m--> 380\u001b[0m         (indices_dataset, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepeat())\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data\n\u001b[1;32m    386\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:735\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensors\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m  `from_tensors` produces a dataset containing only a single element. To slice\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4827\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m   4825\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure, element)\n\u001b[1;32m   4826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m-> 4827\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4828\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4829\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;28msuper\u001b[39m(TensorDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py:7773\u001b[0m, in \u001b[0;36mtensor_dataset\u001b[0;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   7771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   7772\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7773\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7774\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   7777\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "if restart == \"yes\":\n",
    "    print(\"restarting from era, epoch #\", restart_era, restart_epoch)\n",
    "    load_model(model_name + '.era_' + str(era).zfill(3) + '.epoch_'+ str(epoch).zfill(3) + '.h5')\n",
    "\n",
    "for era in range(restart_era, eras):\n",
    "    print(\"*\" * 50)\n",
    "    print(era, \"/\", era, \" ERAS\")\n",
    "    for epoch in range(restart_epoch, epochs):\n",
    "        print(\"=\" * 50)\n",
    "        print(epoch, \"/\", epochs, \" EPOCHS\")\n",
    "        acc = []\n",
    "\n",
    "        for X_train_bulk, Y_train_bulk in get_bulk(X_train, Y_train, images_per_bulk):\n",
    "            for X_batch, Y_batch in get_batch(X_train_bulk, Y_train_bulk, images_per_batch):\n",
    "                print('Training start for a batch')\n",
    "                # normalize data\n",
    "                X_batch = X_batch.astype('float32')\n",
    "                X_batch /= 255\n",
    "                Y_batch = Y_batch.astype('float32')\n",
    "                Y_batch /= 255\n",
    "                model.train_on_batch(X_batch, Y_batch)\n",
    "                score = model.evaluate(X_batch, Y_batch)\n",
    "                print(\"batch accuracy:\", score)\n",
    "                acc.append(score)#\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "        print(\"Train accuracy (mean)\", np.mean(acc))\n",
    "        print(\"Train accuracy (max)\", np.max(acc))\n",
    "        with open(model_name + '.era_' + str(era).zfill(3) + '.epoch_'+ str(epoch).zfill(3) + '.txt', mode='w') as f:\n",
    "            print(\"era: \", era, \" epoch: \", epoch, \" Train accuracy (mean): \", np.mean(acc), \" Train accuracy (max): \", np.max(acc), file=f)\n",
    "        model.save(model_name + '.era_' + str(era).zfill(3) + '.epoch_'+ str(epoch).zfill(3) + '.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
