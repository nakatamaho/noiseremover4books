{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease                         \n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]      \n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Fetched 336 kB in 2s (173 kB/s)  \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Calculating upgrade... Done\n",
      "The following packages have been kept back:\n",
      "  libnvinfer-plugin7 libnvinfer7\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libgl1-mesa-dev is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libglib2.0-0 is already the newest version (2.64.6-1~ubuntu20.04.4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get upgrade -y\n",
    "!apt install -y libgl1-mesa-dev\n",
    "!apt install -y libglib2.0-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tqdm\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 19 02:26:41 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   32C    P8    18W / 340W |     17MiB / 10240MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import ImageFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 for GeForce RTX 3080 10GB\n",
    "#55 for V100 40GB\n",
    "images_per_batch = 14\n",
    "window_width = 256\n",
    "window_height = 256\n",
    "model_name=\"00/scannoise_remover_model\"\n",
    "era_name=\"00/scannoise_remover_era\"\n",
    "make_noised_images = \"no\"\n",
    "make_image_split = \"no\"\n",
    "noise_algorithm = \"new\"\n",
    "groundtruthdir=\"/work/groundtruth/\"\n",
    "cleanimagedir=\"/work/clean/\"\n",
    "noisedimagedir=\"/work/noised/\"\n",
    "epochs = 200\n",
    "eras = 100\n",
    "images_per_bulk = images_per_batch * 100\n",
    "validation_percent = 20\n",
    "restart_era = 5\n",
    "restart_epoch = 0\n",
    "testimages_max = 3000\n",
    "if restart_epoch != 0 or restart_era !=0:\n",
    "    restart = \"yes\"\n",
    "else:\n",
    "    restart = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linenoise(filename, out_dirname):\n",
    "\n",
    "    sigma = 0.35\n",
    "    max_thickness = 20\n",
    "    min_thickness = 8\n",
    "    center_high = 24\n",
    "    center_low = 6\n",
    "\n",
    "    image_orig = cv2.imread(filename)\n",
    "    height, width, c = image_orig.shape\n",
    "    avarage_pixel = int (np.array(image_orig, dtype='float32').sum()/(height*width)/3.)\n",
    "\n",
    "    output_filename_woext = os.path.splitext(os.path.basename(filename))[0]\n",
    "    output_dir = os.path.split(os.path.dirname(filename))\n",
    "    os.makedirs(out_dirname +\"/\" + output_dir[-1], exist_ok=True)\n",
    "\n",
    "    counter = 0\n",
    "    while True:\n",
    "        randline_img = image_orig.copy()\n",
    "        randline_img = np.array(randline_img, dtype='float32')\n",
    "        thickness=random.randint(1,max_thickness/2)*2+1\n",
    "        rand_x=random.randint(      thickness - int(thickness/2) - 1, width - int(thickness/2) - 1)\n",
    "        __col = random.randint(0,7)\n",
    "        _r = __col % 2\n",
    "        _g = (__col >> 1) % 2\n",
    "        _b = (__col >> 2) % 2\n",
    "        _flag = random.randrange(-1,2,2)\n",
    "        if avarage_pixel > 200 and _flag == 1:\n",
    "            _flag = -1\n",
    "        if avarage_pixel < 60 and _flag == -1:\n",
    "            _flag = 1\n",
    "        weight_center = random.randrange(center_low,center_high)/100.\n",
    "        variance_high = int(weight_center*100.)\n",
    "        variance_low = int(weight_center*100. * 0.85)\n",
    "        weight_width = variance_high/100.0 - random.randrange(variance_low,variance_high)/100.\n",
    "\n",
    "        for __x in range(thickness):\n",
    "            _x = __x - int(thickness/2)\n",
    "            distance_from_center = - (int(thickness/2) - abs(_x) ) / int(thickness/2) + 1\n",
    "            gauss_dist = math.exp ( - (distance_from_center) **2  / (2.0 * sigma **2 ) )\n",
    "            for _y in range(height):\n",
    "                _col = randline_img[_y, rand_x + _x]\n",
    "                weight = random.triangular(weight_center-weight_width, weight_center+weight_width, weight_center)\n",
    "                _col[0] = (_r * 255.) * gauss_dist * _flag * weight + _col [0]\n",
    "                _col[1] = (_g * 255.) * gauss_dist * _flag * weight + _col [1]\n",
    "                _col[2] = (_b * 255.) * gauss_dist * _flag * weight + _col [2]\n",
    "                if _col[0] > 255.:\n",
    "                    _col[0] = 255.\n",
    "                if _col[1] > 255.:\n",
    "                    _col[1] = 255.\n",
    "                if _col[2] > 255.:\n",
    "                    _col[2] = 255.\n",
    "                if _col[0] < 0.:\n",
    "                    _col[0] = 0.\n",
    "                if _col[1] < 0.:\n",
    "                    _col[1] = 0.\n",
    "                if _col[2] < 0.:\n",
    "                    _col[2] = 0.\n",
    "                randline_img[_y, rand_x + _x] = _col\n",
    "        randline_img = np.array(randline_img, dtype='int16')\n",
    "        orig_img = np.array(image_orig, dtype='int16')\n",
    "        randline_img_rgb = randline_img[:,:,0]+randline_img[:,:,1]+randline_img[:,:,2]\n",
    "        orig_img_rgb = orig_img[:,:,0]+orig_img[:,:,1]+orig_img[:,:,2]\n",
    "\n",
    "        diff = np.abs(randline_img_rgb - orig_img_rgb)\n",
    "        diff_max = diff.max()\n",
    "        diff_sum = diff.sum()\n",
    "        if diff_sum < 1200 or diff_max < 30:\n",
    "            counter = counter + 1\n",
    "            if counter > 10:\n",
    "                print(\"diff_max, diff_sum, _flag, weight_center, weight_width, thickness, average_pixel\",  output_filename_woext, diff_max, diff_sum, _flag, weight_center, weight_width, thickness, avarage_pixel)\n",
    "            continue\n",
    "        else:\n",
    "            #print(\"absmax, sum, _flag, weight_center, weight_width, thickness\",  output_filename_woext, diff_max, diff_sum, _flag,\n",
    "            #weight_center, weight_width, thickness, avarage_pixel)\n",
    "            #print(\"ok\")\n",
    "            randline_img = np.array(randline_img, dtype='uint8')\n",
    "            cv2.imwrite(out_dirname +\"/\" + output_dir[-1] + \"/\" + output_filename_woext+\".png\",randline_img)\n",
    "            return (filename, rand_x, _flag, weight_center, weight_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgSplit(filename, out_dirname):\n",
    "    height = window_height\n",
    "    width = window_width\n",
    "    \n",
    "    im = cv2.imread(filename)\n",
    "    output_filename_woext = os.path.splitext(os.path.basename(filename))[0]\n",
    "    output_dir = os.path.split(os.path.dirname(filename))\n",
    "    os.makedirs(out_dirname +\"/\" + output_dir[-1], exist_ok=True) \n",
    "    img_height, img_width = im.shape[:2]\n",
    "    # do not make a patch when image patch is too small\n",
    "    if (img_height < window_height) or (img_width < window_width):\n",
    "        return\n",
    "    split_height = int(img_height / height) \n",
    "    split_width = int(img_width / width)\n",
    "    for h1 in range(split_height+1):\n",
    "        for w1 in range(split_width+1):\n",
    "            w2 = w1 * width\n",
    "            h2 = h1 * height\n",
    "            _h_start = h2\n",
    "            _h_end   = height+h2-1\n",
    "            _w_start = w2\n",
    "            _w_end   = width+w2-1\n",
    "            if h1 == split_height:\n",
    "                _h_start = img_height-height\n",
    "                _h_end   = img_height-1\n",
    "            if w1 == split_width:\n",
    "                _w_start = img_width-width\n",
    "                _w_end   = img_width-1\n",
    "            c = im[_h_start:_h_end+1, _w_start:_w_end+1]\n",
    "            if (_h_end+1 - _h_start) == height and (_w_end+1 - _w_start) == width:\n",
    "                cv2.imwrite(out_dirname +\"/\" + output_dir[-1] + \"/\" + output_filename_woext + \"_\" + str(h1).zfill(3) + \"_\" + str(w1).zfill(3) +\".png\",c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do not make testimages\n"
     ]
    }
   ],
   "source": [
    "if make_image_split != \"no\":\n",
    "    print(\"making testimages\")\n",
    "    filenames_list=glob.glob(groundtruthdir + \"/*/*.jpg\")\n",
    "    try:\n",
    "        shutil.rmtree(cleanimagedir)\n",
    "    except OSError as e:\n",
    "        pass    \n",
    "    pathlib.Path(cleanimagedir).mkdir()\n",
    "    \n",
    "    for _filename in tqdm.tqdm(filenames_list):\n",
    "        ImgSplit(_filename, out_dirname = cleanimagedir)\n",
    "else:\n",
    "    print(\"do not make testimages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if make_noised_images != \"no\":\n",
    "    print(\"making noised images\")\n",
    "    try:\n",
    "        shutil.rmtree(noisedimagedir)       \n",
    "    except OSError as e:\n",
    "        pass\n",
    "    pathlib.Path(noisedimagedir).mkdir()\n",
    "    filenames_list=glob.glob(cleanimagedir + \"*/*.png\")\n",
    "    for _filename in tqdm.tqdm(filenames_list):\n",
    "        if noise_algorithm == \"old\":\n",
    "            #print(\"using old noise algorithm\")\n",
    "            pp = add_linenoise_old(_filename, out_dirname = noisedimagedir)\n",
    "        else:\n",
    "            #print(\"using new noise algorithm\")\n",
    "            pp = add_linenoise(_filename, out_dirname = noisedimagedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images 856074\n"
     ]
    }
   ],
   "source": [
    "filenames_train_list=sorted(glob.glob(noisedimagedir + \"*/*.png\"))\n",
    "filenames_target_list=sorted(glob.glob(cleanimagedir + \"*/*.png\"))\n",
    "counter_train = len(filenames_train_list)\n",
    "counter_target = len(filenames_target_list)\n",
    "if (counter_train != counter_target):\n",
    "    print(\"something wrong in num of pics of target and trains\")\n",
    "    exit(1)\n",
    "numof_train = int(counter_target * (100.0-validation_percent) / 100.0 )\n",
    "numof_validation = counter_target - numof_train\n",
    "print(\"total images\",counter_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restarting from era, epoch # 5 0\n",
      "current era images:  45687  restart_era:  5\n",
      "next era images:  810387\n"
     ]
    }
   ],
   "source": [
    "if restart == \"yes\":\n",
    "    print(\"restarting from era, epoch #\", restart_era, restart_epoch)\n",
    "    era_pickle_file_current=era_name + '.' + str(restart_era).zfill(3) +'.current.pickle'\n",
    "    era_pickle_file_nextcal=era_name + '.' + str(restart_era).zfill(3) +'.nextcal.pickle'\n",
    "    with open(era_pickle_file_current, mode='rb') as f:\n",
    "        ERA_X = pickle.load(f)\n",
    "    with open(era_pickle_file_nextcal, mode='rb') as f:\n",
    "        ERA_X_next = pickle.load(f)\n",
    "    print(\"current era images: \", len(ERA_X), \" restart_era: \", restart_era)\n",
    "    print(\"next era images: \",len(ERA_X_next))\n",
    "\n",
    "else:\n",
    "    numof_total_files = len(filenames_train_list)\n",
    "    numof_1st_era_x= numof_total_files-int(counter_target * 0.01)\n",
    "    ERA_X, ERA_X_next= train_test_split(filenames_train_list, test_size=numof_1st_era_x, random_state=42) #from sklearn\n",
    "\n",
    "    era_pickle_file_current=era_name + '.' + str(0).zfill(3) +'.current.pickle'\n",
    "    era_pickle_file_nextcal=era_name + '.' + str(0).zfill(3) +'.nextcal.pickle'\n",
    "\n",
    "    with open(era_pickle_file_current, mode='wb') as f:\n",
    "        pickle.dump(ERA_X, f)\n",
    "    with open(era_pickle_file_nextcal, mode='wb') as f:\n",
    "        pickle.dump(ERA_X_next, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(_X_train, _Y_train, _images_per_batch):\n",
    "    print(\"getting a batch\")\n",
    "    print(\"images per batch\", _images_per_batch)\n",
    "    numof_batchs = len(_X_train)//_images_per_batch\n",
    "    print(\"Number of batches\", numof_batchs)\n",
    "\n",
    "    i = 0\n",
    "    while (i < numof_batchs):\n",
    "        print(\"doing a batch of \", i, \"/\", numof_batchs)\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        Y_batch = _Y_train[(i * _images_per_batch):(i * _images_per_batch + _images_per_batch)]\n",
    "        X_batch = _X_train[(i * _images_per_batch):(i * _images_per_batch + _images_per_batch)]\n",
    "        i += 1\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bulk(_X_train, _Y_train, _images_per_bulk):\n",
    "    print(\"images per bluk\", _images_per_bulk)\n",
    "    numof_bulks = len(_X_train)// _images_per_bulk\n",
    "    print(\"Number of bulks\", numof_bulks)\n",
    "    i = 0\n",
    "    while (i < numof_bulks):\n",
    "        print(\"doing a bulk of \", i, \"/\", numof_bulks)\n",
    "        X_train_bulk = []\n",
    "        Y_train_bulk = []\n",
    "        X_train_bulk_name = []\n",
    "        Y_train_bulk_name = []\n",
    "        print(\"getting a bluk...start \")\n",
    "        X_train_name = _X_train[(i * _images_per_bulk):(i * _images_per_bulk + _images_per_bulk)]\n",
    "        Y_train_name = _Y_train[(i * _images_per_bulk):(i * _images_per_bulk + _images_per_bulk)]\n",
    "        X_train_bulk = np.array([np.array(Image.open(file)) for file in X_train_name])\n",
    "        Y_train_bulk = np.array([np.array(Image.open(file)) for file in Y_train_name])\n",
    "        print(\"getting a bluk...done \")\n",
    "\n",
    "        i += 1\n",
    "        yield X_train_bulk, Y_train_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split noised data to training and test (validation) sets\n",
    "X_train, x_test= train_test_split(ERA_X, test_size=validation_percent, random_state=42) #from sklearn\n",
    "Y_train = [s.replace(noisedimagedir, cleanimagedir) for s in X_train]\n",
    "y_test = [s.replace(noisedimagedir, cleanimagedir) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(window_height, window_width, 3))\n",
    "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "for i in range(15):\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(3, (3, 3), padding='same')(x)\n",
    "output_img = Activation('tanh')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_img, output_img)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restarting from era, epoch # 5 0\n",
      "**************************************************\n",
      "5 / 5  ERAS\n",
      "==================================================\n",
      "0 / 200  EPOCHS\n",
      "images per bluk 1400\n",
      "Number of bulks 32\n",
      "doing a bulk of  0 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.6431\n",
      "batch accuracy: 0.6431452035903931\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5665\n",
      "batch accuracy: 0.566451370716095\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4274\n",
      "batch accuracy: 0.42738577723503113\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5814\n",
      "batch accuracy: 0.5814301371574402\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5533\n",
      "batch accuracy: 0.5532615184783936\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4134\n",
      "batch accuracy: 0.4133620858192444\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5636\n",
      "batch accuracy: 0.5635549426078796\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4339\n",
      "batch accuracy: 0.43390974402427673\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4195\n",
      "batch accuracy: 0.4194658398628235\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3821\n",
      "batch accuracy: 0.38213521242141724\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3006\n",
      "batch accuracy: 0.30064281821250916\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2603\n",
      "batch accuracy: 0.2602740228176117\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2540\n",
      "batch accuracy: 0.2539718449115753\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2247\n",
      "batch accuracy: 0.22466601431369781\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2013\n",
      "batch accuracy: 0.2013368308544159\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1620\n",
      "batch accuracy: 0.161968395113945\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1128\n",
      "batch accuracy: 0.11278848350048065\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1295\n",
      "batch accuracy: 0.12946848571300507\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1103\n",
      "batch accuracy: 0.11029144376516342\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0802\n",
      "batch accuracy: 0.08020658791065216\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0954\n",
      "batch accuracy: 0.09538529068231583\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0760\n",
      "batch accuracy: 0.07598267495632172\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0625\n",
      "batch accuracy: 0.06245240569114685\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0867\n",
      "batch accuracy: 0.08665218204259872\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0636\n",
      "batch accuracy: 0.06360995024442673\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0671\n",
      "batch accuracy: 0.0671384409070015\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0501\n",
      "batch accuracy: 0.05008048564195633\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0498\n",
      "batch accuracy: 0.049765992909669876\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0620\n",
      "batch accuracy: 0.061951614916324615\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0616\n",
      "batch accuracy: 0.06158725544810295\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0872\n",
      "batch accuracy: 0.08718453347682953\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0594\n",
      "batch accuracy: 0.059449177235364914\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0345\n",
      "batch accuracy: 0.034548405557870865\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0478\n",
      "batch accuracy: 0.047750379890203476\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0503\n",
      "batch accuracy: 0.05028541758656502\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0773\n",
      "batch accuracy: 0.07725819200277328\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0511\n",
      "batch accuracy: 0.051073115319013596\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0567\n",
      "batch accuracy: 0.056714143604040146\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0544\n",
      "batch accuracy: 0.05440547689795494\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0339\n",
      "batch accuracy: 0.033947523683309555\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0369\n",
      "batch accuracy: 0.03693684563040733\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0514\n",
      "batch accuracy: 0.05139732360839844\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0664\n",
      "batch accuracy: 0.06637584418058395\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0355\n",
      "batch accuracy: 0.03553033247590065\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0673\n",
      "batch accuracy: 0.06734291464090347\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0613\n",
      "batch accuracy: 0.06131656840443611\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0477\n",
      "batch accuracy: 0.047655586153268814\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0610\n",
      "batch accuracy: 0.0609518401324749\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0553\n",
      "batch accuracy: 0.05532590299844742\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0347\n",
      "batch accuracy: 0.03473036363720894\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0329\n",
      "batch accuracy: 0.03292619809508324\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0280\n",
      "batch accuracy: 0.028021544218063354\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0508\n",
      "batch accuracy: 0.05078047513961792\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0472\n",
      "batch accuracy: 0.047155823558568954\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0286\n",
      "batch accuracy: 0.028560152277350426\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0366\n",
      "batch accuracy: 0.0365958996117115\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0600\n",
      "batch accuracy: 0.06000092625617981\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0575\n",
      "batch accuracy: 0.05749432370066643\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0362\n",
      "batch accuracy: 0.03620022535324097\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0333\n",
      "batch accuracy: 0.03333204612135887\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0622\n",
      "batch accuracy: 0.06222609803080559\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0529\n",
      "batch accuracy: 0.05292127653956413\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0649\n",
      "batch accuracy: 0.06487759202718735\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0615\n",
      "batch accuracy: 0.0615074560046196\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0442\n",
      "batch accuracy: 0.044244732707738876\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0787\n",
      "batch accuracy: 0.07871902734041214\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0475\n",
      "batch accuracy: 0.04751315340399742\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0617\n",
      "batch accuracy: 0.06169256195425987\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0821\n",
      "batch accuracy: 0.08206946402788162\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0512\n",
      "batch accuracy: 0.051155317574739456\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0821\n",
      "batch accuracy: 0.08213812857866287\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0831\n",
      "batch accuracy: 0.08312814682722092\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0577\n",
      "batch accuracy: 0.057701475918293\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0609\n",
      "batch accuracy: 0.06086374446749687\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0399\n",
      "batch accuracy: 0.03992396593093872\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0593\n",
      "batch accuracy: 0.059347011148929596\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0710\n",
      "batch accuracy: 0.07095477730035782\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0579\n",
      "batch accuracy: 0.057870056480169296\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0759\n",
      "batch accuracy: 0.07593400031328201\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0575\n",
      "batch accuracy: 0.05749361962080002\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0526\n",
      "batch accuracy: 0.05256718024611473\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0606\n",
      "batch accuracy: 0.0605844184756279\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0466\n",
      "batch accuracy: 0.04663326218724251\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0714\n",
      "batch accuracy: 0.07136411219835281\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0756\n",
      "batch accuracy: 0.07560350745916367\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0716\n",
      "batch accuracy: 0.07162471115589142\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0380\n",
      "batch accuracy: 0.037987399846315384\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0631\n",
      "batch accuracy: 0.06311310827732086\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0453\n",
      "batch accuracy: 0.045297738164663315\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0708\n",
      "batch accuracy: 0.07076645642518997\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0500\n",
      "batch accuracy: 0.049978528171777725\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0406\n",
      "batch accuracy: 0.04055413231253624\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0456\n",
      "batch accuracy: 0.04558435454964638\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0246\n",
      "batch accuracy: 0.024626990780234337\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0605\n",
      "batch accuracy: 0.06049766391515732\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0423\n",
      "batch accuracy: 0.04226450249552727\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0437\n",
      "batch accuracy: 0.04370161518454552\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0652\n",
      "batch accuracy: 0.06518234312534332\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0644\n",
      "batch accuracy: 0.06436420232057571\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0651\n",
      "batch accuracy: 0.06512673944234848\n",
      "doing a bulk of  1 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0470\n",
      "batch accuracy: 0.04704165458679199\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0714\n",
      "batch accuracy: 0.07142140716314316\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0449\n",
      "batch accuracy: 0.044893037527799606\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0505\n",
      "batch accuracy: 0.05045907944440842\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0525\n",
      "batch accuracy: 0.05249648913741112\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0477\n",
      "batch accuracy: 0.04772612079977989\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0498\n",
      "batch accuracy: 0.04981255531311035\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0660\n",
      "batch accuracy: 0.06595419347286224\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0610\n",
      "batch accuracy: 0.060958292335271835\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0404\n",
      "batch accuracy: 0.0404396653175354\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0616\n",
      "batch accuracy: 0.061577171087265015\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0419\n",
      "batch accuracy: 0.04190600663423538\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0457\n",
      "batch accuracy: 0.045678164809942245\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0833\n",
      "batch accuracy: 0.08332952111959457\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0609\n",
      "batch accuracy: 0.06085142120718956\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0345\n",
      "batch accuracy: 0.03451846167445183\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0800\n",
      "batch accuracy: 0.0800415650010109\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0489\n",
      "batch accuracy: 0.048906538635492325\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0815\n",
      "batch accuracy: 0.08154616504907608\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0602\n",
      "batch accuracy: 0.06024175509810448\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0653\n",
      "batch accuracy: 0.06531233340501785\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0404\n",
      "batch accuracy: 0.040396757423877716\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0598\n",
      "batch accuracy: 0.0597807839512825\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0640\n",
      "batch accuracy: 0.06401530653238297\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0490\n",
      "batch accuracy: 0.04897695034742355\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0484\n",
      "batch accuracy: 0.04843628779053688\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0385\n",
      "batch accuracy: 0.0385056734085083\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0504\n",
      "batch accuracy: 0.050449907779693604\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0491\n",
      "batch accuracy: 0.0491287037730217\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0590\n",
      "batch accuracy: 0.05900374427437782\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0726\n",
      "batch accuracy: 0.07259144634008408\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0516\n",
      "batch accuracy: 0.05156037211418152\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0689\n",
      "batch accuracy: 0.06893307715654373\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0531\n",
      "batch accuracy: 0.05311939865350723\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0645\n",
      "batch accuracy: 0.06449273228645325\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0718\n",
      "batch accuracy: 0.0718105286359787\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0366\n",
      "batch accuracy: 0.03660896420478821\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0529\n",
      "batch accuracy: 0.052903659641742706\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0514\n",
      "batch accuracy: 0.05144767090678215\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0573\n",
      "batch accuracy: 0.057305097579956055\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0773\n",
      "batch accuracy: 0.07727140933275223\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0867\n",
      "batch accuracy: 0.08673954010009766\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0591\n",
      "batch accuracy: 0.059128496795892715\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0504\n",
      "batch accuracy: 0.0503731332719326\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0451\n",
      "batch accuracy: 0.045081306248903275\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0828\n",
      "batch accuracy: 0.08277827501296997\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0475\n",
      "batch accuracy: 0.047476254403591156\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0490\n",
      "batch accuracy: 0.04904182627797127\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0546\n",
      "batch accuracy: 0.054572101682424545\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0667\n",
      "batch accuracy: 0.06674282252788544\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1049\n",
      "batch accuracy: 0.10491462051868439\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0431\n",
      "batch accuracy: 0.043086323887109756\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0339\n",
      "batch accuracy: 0.03386949747800827\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0460\n",
      "batch accuracy: 0.045990023761987686\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1022\n",
      "batch accuracy: 0.10223988443613052\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0420\n",
      "batch accuracy: 0.04197282716631889\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0590\n",
      "batch accuracy: 0.05899432674050331\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0346\n",
      "batch accuracy: 0.03461212292313576\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0454\n",
      "batch accuracy: 0.04540777578949928\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0704\n",
      "batch accuracy: 0.07040461152791977\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0670\n",
      "batch accuracy: 0.06702025234699249\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0548\n",
      "batch accuracy: 0.054810088127851486\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0369\n",
      "batch accuracy: 0.036863505840301514\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0512\n",
      "batch accuracy: 0.05118193104863167\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0486\n",
      "batch accuracy: 0.048600468784570694\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0509\n",
      "batch accuracy: 0.050938867032527924\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0565\n",
      "batch accuracy: 0.056503865867853165\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0409\n",
      "batch accuracy: 0.040906209498643875\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0352\n",
      "batch accuracy: 0.03516561537981033\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0651\n",
      "batch accuracy: 0.06514845788478851\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0305\n",
      "batch accuracy: 0.030482277274131775\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0358\n",
      "batch accuracy: 0.03575355187058449\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0302\n",
      "batch accuracy: 0.030248960480093956\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0347\n",
      "batch accuracy: 0.034720681607723236\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0431\n",
      "batch accuracy: 0.04313671588897705\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0807\n",
      "batch accuracy: 0.08068350702524185\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0478\n",
      "batch accuracy: 0.04782840982079506\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0491\n",
      "batch accuracy: 0.049117498099803925\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0358\n",
      "batch accuracy: 0.03582033887505531\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0360\n",
      "batch accuracy: 0.03595362976193428\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0314\n",
      "batch accuracy: 0.031437840312719345\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0282\n",
      "batch accuracy: 0.02820870466530323\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0317\n",
      "batch accuracy: 0.03173412010073662\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0263\n",
      "batch accuracy: 0.026313677430152893\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0413\n",
      "batch accuracy: 0.04127070680260658\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0373\n",
      "batch accuracy: 0.03730195760726929\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0405\n",
      "batch accuracy: 0.04050204157829285\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0346\n",
      "batch accuracy: 0.034582145512104034\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0410\n",
      "batch accuracy: 0.041021961718797684\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0315\n",
      "batch accuracy: 0.03150288388133049\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0439\n",
      "batch accuracy: 0.043862201273441315\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0488\n",
      "batch accuracy: 0.04882020503282547\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0469\n",
      "batch accuracy: 0.04690692201256752\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0555\n",
      "batch accuracy: 0.0554877333343029\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0575\n",
      "batch accuracy: 0.057517439126968384\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0399\n",
      "batch accuracy: 0.03992112725973129\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0511\n",
      "batch accuracy: 0.05106735974550247\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0470\n",
      "batch accuracy: 0.04703369736671448\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0352\n",
      "batch accuracy: 0.0351887010037899\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0440\n",
      "batch accuracy: 0.04400375112891197\n",
      "doing a bulk of  2 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0485\n",
      "batch accuracy: 0.048531804233789444\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0444\n",
      "batch accuracy: 0.04440915957093239\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0747\n",
      "batch accuracy: 0.07469834387302399\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0298\n",
      "batch accuracy: 0.02979918196797371\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0361\n",
      "batch accuracy: 0.03610582277178764\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0570\n",
      "batch accuracy: 0.05702424794435501\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0385\n",
      "batch accuracy: 0.03852734714746475\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0249\n",
      "batch accuracy: 0.024922983720898628\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0473\n",
      "batch accuracy: 0.0473005585372448\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0341\n",
      "batch accuracy: 0.03407538682222366\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0474\n",
      "batch accuracy: 0.04737419635057449\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0347\n",
      "batch accuracy: 0.03473446145653725\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0362\n",
      "batch accuracy: 0.03619232773780823\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0570\n",
      "batch accuracy: 0.056973185390233994\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0378\n",
      "batch accuracy: 0.0378258116543293\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0442\n",
      "batch accuracy: 0.044186752289533615\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0461\n",
      "batch accuracy: 0.04609500989317894\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0329\n",
      "batch accuracy: 0.03290124982595444\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0524\n",
      "batch accuracy: 0.05235627666115761\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0282\n",
      "batch accuracy: 0.028225060552358627\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0272\n",
      "batch accuracy: 0.027241572737693787\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0276\n",
      "batch accuracy: 0.02757745422422886\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0395\n",
      "batch accuracy: 0.03954160213470459\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0378\n",
      "batch accuracy: 0.03776406869292259\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0468\n",
      "batch accuracy: 0.04677903279662132\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0339\n",
      "batch accuracy: 0.033910635858774185\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0365\n",
      "batch accuracy: 0.03645642474293709\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0496\n",
      "batch accuracy: 0.049553610384464264\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0466\n",
      "batch accuracy: 0.04661765322089195\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0457\n",
      "batch accuracy: 0.04571414366364479\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0630\n",
      "batch accuracy: 0.06302552670240402\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0349\n",
      "batch accuracy: 0.034895703196525574\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0275\n",
      "batch accuracy: 0.027455849573016167\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0280\n",
      "batch accuracy: 0.027973400428891182\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0316\n",
      "batch accuracy: 0.03155866637825966\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0327\n",
      "batch accuracy: 0.03273426741361618\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0221\n",
      "batch accuracy: 0.02206096611917019\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0455\n",
      "batch accuracy: 0.04547428339719772\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0361\n",
      "batch accuracy: 0.03606254979968071\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0490\n",
      "batch accuracy: 0.04895297437906265\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0329\n",
      "batch accuracy: 0.03293294087052345\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0305\n",
      "batch accuracy: 0.03048175759613514\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0305\n",
      "batch accuracy: 0.030479470267891884\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0483\n",
      "batch accuracy: 0.04828682169318199\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0250\n",
      "batch accuracy: 0.024984823539853096\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0441\n",
      "batch accuracy: 0.04407908767461777\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0434\n",
      "batch accuracy: 0.043418291956186295\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0342\n",
      "batch accuracy: 0.034218329936265945\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0232\n",
      "batch accuracy: 0.023152276873588562\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0186\n",
      "batch accuracy: 0.018551241606473923\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0423\n",
      "batch accuracy: 0.042261961847543716\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0190\n",
      "batch accuracy: 0.01895820163190365\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0325\n",
      "batch accuracy: 0.032497588545084\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0146\n",
      "batch accuracy: 0.014644778333604336\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0185\n",
      "batch accuracy: 0.018492531031370163\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0155\n",
      "batch accuracy: 0.015524023212492466\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0152\n",
      "batch accuracy: 0.015199805609881878\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0174\n",
      "batch accuracy: 0.01735115796327591\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0262\n",
      "batch accuracy: 0.026189347729086876\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0306\n",
      "batch accuracy: 0.030566679313778877\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0408\n",
      "batch accuracy: 0.040838807821273804\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0329\n",
      "batch accuracy: 0.032869867980480194\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0359\n",
      "batch accuracy: 0.035914670675992966\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0321\n",
      "batch accuracy: 0.03212888166308403\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0247\n",
      "batch accuracy: 0.024686945602297783\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0414\n",
      "batch accuracy: 0.04142729192972183\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0391\n",
      "batch accuracy: 0.03914937749505043\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0373\n",
      "batch accuracy: 0.03731527924537659\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0549\n",
      "batch accuracy: 0.05488622188568115\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0849\n",
      "batch accuracy: 0.08494348078966141\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0775\n",
      "batch accuracy: 0.07748042047023773\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0704\n",
      "batch accuracy: 0.07037647813558578\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0754\n",
      "batch accuracy: 0.0753776878118515\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1021\n",
      "batch accuracy: 0.10205583274364471\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0795\n",
      "batch accuracy: 0.0795445516705513\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0648\n",
      "batch accuracy: 0.06484293937683105\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0483\n",
      "batch accuracy: 0.04827693849802017\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0802\n",
      "batch accuracy: 0.08019216358661652\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0569\n",
      "batch accuracy: 0.056893911212682724\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0565\n",
      "batch accuracy: 0.05648287385702133\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0558\n",
      "batch accuracy: 0.055760014802217484\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0635\n",
      "batch accuracy: 0.06345761567354202\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0564\n",
      "batch accuracy: 0.05636821314692497\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0616\n",
      "batch accuracy: 0.0615575909614563\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0918\n",
      "batch accuracy: 0.09182675182819366\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0735\n",
      "batch accuracy: 0.07351012527942657\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0714\n",
      "batch accuracy: 0.07135987281799316\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0909\n",
      "batch accuracy: 0.09085293859243393\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0631\n",
      "batch accuracy: 0.06307006627321243\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0705\n",
      "batch accuracy: 0.07050307095050812\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0614\n",
      "batch accuracy: 0.06136588379740715\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0729\n",
      "batch accuracy: 0.07287870347499847\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0752\n",
      "batch accuracy: 0.07515180855989456\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0732\n",
      "batch accuracy: 0.0731888934969902\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0801\n",
      "batch accuracy: 0.08006979525089264\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0775\n",
      "batch accuracy: 0.07753128558397293\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0860\n",
      "batch accuracy: 0.08603537082672119\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0873\n",
      "batch accuracy: 0.08730445802211761\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0676\n",
      "batch accuracy: 0.06761009991168976\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0512\n",
      "batch accuracy: 0.051232900470495224\n",
      "doing a bulk of  3 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0640\n",
      "batch accuracy: 0.06397128850221634\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0551\n",
      "batch accuracy: 0.05513091757893562\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0549\n",
      "batch accuracy: 0.05494043231010437\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0610\n",
      "batch accuracy: 0.06100274249911308\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0728\n",
      "batch accuracy: 0.07282687723636627\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0688\n",
      "batch accuracy: 0.06884028017520905\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1045\n",
      "batch accuracy: 0.10454469174146652\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0905\n",
      "batch accuracy: 0.0905066579580307\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0931\n",
      "batch accuracy: 0.09306353330612183\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0864\n",
      "batch accuracy: 0.08637045323848724\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0927\n",
      "batch accuracy: 0.09273433685302734\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0800\n",
      "batch accuracy: 0.0800003781914711\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0825\n",
      "batch accuracy: 0.0825146809220314\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0504\n",
      "batch accuracy: 0.05038123577833176\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0547\n",
      "batch accuracy: 0.05473080649971962\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0473\n",
      "batch accuracy: 0.047345902770757675\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0528\n",
      "batch accuracy: 0.052803125232458115\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0389\n",
      "batch accuracy: 0.03886588290333748\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0246\n",
      "batch accuracy: 0.02459121122956276\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0513\n",
      "batch accuracy: 0.05132002755999565\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0536\n",
      "batch accuracy: 0.053581688553094864\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0550\n",
      "batch accuracy: 0.05498886480927467\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0611\n",
      "batch accuracy: 0.061115771532058716\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0565\n",
      "batch accuracy: 0.05646927282214165\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0859\n",
      "batch accuracy: 0.08589465171098709\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0509\n",
      "batch accuracy: 0.050934549421072006\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0599\n",
      "batch accuracy: 0.05993913486599922\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0798\n",
      "batch accuracy: 0.07984007894992828\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0651\n",
      "batch accuracy: 0.06507156789302826\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0683\n",
      "batch accuracy: 0.0682564303278923\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0754\n",
      "batch accuracy: 0.07535286247730255\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0610\n",
      "batch accuracy: 0.06099527329206467\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0844\n",
      "batch accuracy: 0.08439964801073074\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0633\n",
      "batch accuracy: 0.06332846730947495\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0584\n",
      "batch accuracy: 0.058400146663188934\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0673\n",
      "batch accuracy: 0.06725083291530609\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0521\n",
      "batch accuracy: 0.052098535001277924\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0552\n",
      "batch accuracy: 0.05523370951414108\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0661\n",
      "batch accuracy: 0.06614707410335541\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0728\n",
      "batch accuracy: 0.07283545285463333\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0751\n",
      "batch accuracy: 0.07511114329099655\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0631\n",
      "batch accuracy: 0.0631033331155777\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0683\n",
      "batch accuracy: 0.06828393042087555\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0917\n",
      "batch accuracy: 0.09174513816833496\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1153\n",
      "batch accuracy: 0.11528366059064865\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0636\n",
      "batch accuracy: 0.06361187249422073\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0730\n",
      "batch accuracy: 0.07295294106006622\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0755\n",
      "batch accuracy: 0.07547537982463837\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0669\n",
      "batch accuracy: 0.06693270802497864\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0643\n",
      "batch accuracy: 0.06426401436328888\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0544\n",
      "batch accuracy: 0.05440619960427284\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0595\n",
      "batch accuracy: 0.059479717165231705\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0600\n",
      "batch accuracy: 0.06003674492239952\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0584\n",
      "batch accuracy: 0.0584196038544178\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0612\n",
      "batch accuracy: 0.06116688624024391\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0549\n",
      "batch accuracy: 0.054910384118556976\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0679\n",
      "batch accuracy: 0.06785061210393906\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0624\n",
      "batch accuracy: 0.0624043345451355\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0703\n",
      "batch accuracy: 0.07028664648532867\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0481\n",
      "batch accuracy: 0.04812468960881233\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0497\n",
      "batch accuracy: 0.04971259832382202\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0481\n",
      "batch accuracy: 0.04810541868209839\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0499\n",
      "batch accuracy: 0.049889322370290756\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0379\n",
      "batch accuracy: 0.0379144549369812\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0422\n",
      "batch accuracy: 0.042210936546325684\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0478\n",
      "batch accuracy: 0.0477527379989624\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0386\n",
      "batch accuracy: 0.038630515336990356\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0432\n",
      "batch accuracy: 0.043229226022958755\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0429\n",
      "batch accuracy: 0.04294278472661972\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0440\n",
      "batch accuracy: 0.044017016887664795\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0450\n",
      "batch accuracy: 0.04498157650232315\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0456\n",
      "batch accuracy: 0.04563208296895027\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0373\n",
      "batch accuracy: 0.03732868656516075\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0467\n",
      "batch accuracy: 0.046714674681425095\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0508\n",
      "batch accuracy: 0.050751011818647385\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0452\n",
      "batch accuracy: 0.04524356871843338\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0472\n",
      "batch accuracy: 0.047187089920043945\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0453\n",
      "batch accuracy: 0.04533633589744568\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0508\n",
      "batch accuracy: 0.05081847310066223\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0419\n",
      "batch accuracy: 0.041941601783037186\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0383\n",
      "batch accuracy: 0.038330111652612686\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0371\n",
      "batch accuracy: 0.0371398851275444\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0412\n",
      "batch accuracy: 0.04119549319148064\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0388\n",
      "batch accuracy: 0.03878181800246239\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0343\n",
      "batch accuracy: 0.03434893116354942\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0400\n",
      "batch accuracy: 0.04001856595277786\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0392\n",
      "batch accuracy: 0.03922557085752487\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0407\n",
      "batch accuracy: 0.040690213441848755\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0420\n",
      "batch accuracy: 0.041996002197265625\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0458\n",
      "batch accuracy: 0.0458400584757328\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0430\n",
      "batch accuracy: 0.0429919958114624\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0369\n",
      "batch accuracy: 0.03689297288656235\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0291\n",
      "batch accuracy: 0.02906586416065693\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0288\n",
      "batch accuracy: 0.02878435142338276\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0250\n",
      "batch accuracy: 0.02502518519759178\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0193\n",
      "batch accuracy: 0.019329162314534187\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0284\n",
      "batch accuracy: 0.028425004333257675\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0367\n",
      "batch accuracy: 0.03672918304800987\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0366\n",
      "batch accuracy: 0.036613207310438156\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0451\n",
      "batch accuracy: 0.04511908441781998\n",
      "doing a bulk of  4 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0716\n",
      "batch accuracy: 0.0716191902756691\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0453\n",
      "batch accuracy: 0.04527007415890694\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0291\n",
      "batch accuracy: 0.029116306453943253\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0286\n",
      "batch accuracy: 0.028561517596244812\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0276\n",
      "batch accuracy: 0.027592936530709267\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0224\n",
      "batch accuracy: 0.022365540266036987\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0263\n",
      "batch accuracy: 0.026303665712475777\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0276\n",
      "batch accuracy: 0.027594098821282387\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0279\n",
      "batch accuracy: 0.027859289199113846\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0253\n",
      "batch accuracy: 0.02525218017399311\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0272\n",
      "batch accuracy: 0.02717619575560093\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0267\n",
      "batch accuracy: 0.026692816987633705\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0250\n",
      "batch accuracy: 0.02500568889081478\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0212\n",
      "batch accuracy: 0.02121848240494728\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0182\n",
      "batch accuracy: 0.018190786242485046\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0176\n",
      "batch accuracy: 0.017649471759796143\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0151\n",
      "batch accuracy: 0.015083442442119122\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0193\n",
      "batch accuracy: 0.019306572154164314\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0164\n",
      "batch accuracy: 0.016392339020967484\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0156\n",
      "batch accuracy: 0.015583967790007591\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0121\n",
      "batch accuracy: 0.012129878625273705\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0130\n",
      "batch accuracy: 0.01295950822532177\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0120\n",
      "batch accuracy: 0.011980196461081505\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070\n",
      "batch accuracy: 0.00697109242901206\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0116\n",
      "batch accuracy: 0.01164653617888689\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0118\n",
      "batch accuracy: 0.011792841367423534\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094\n",
      "batch accuracy: 0.009367406368255615\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0121\n",
      "batch accuracy: 0.012093178927898407\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0123\n",
      "batch accuracy: 0.012266897596418858\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0134\n",
      "batch accuracy: 0.013357413001358509\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0141\n",
      "batch accuracy: 0.014067872427403927\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0169\n",
      "batch accuracy: 0.01692713052034378\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0138\n",
      "batch accuracy: 0.013761832378804684\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0212\n",
      "batch accuracy: 0.02117927558720112\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0190\n",
      "batch accuracy: 0.019042057916522026\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0203\n",
      "batch accuracy: 0.020268350839614868\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0209\n",
      "batch accuracy: 0.020931342616677284\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0182\n",
      "batch accuracy: 0.01819949969649315\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0140\n",
      "batch accuracy: 0.014015046879649162\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0148\n",
      "batch accuracy: 0.014800423756241798\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0174\n",
      "batch accuracy: 0.017357537522912025\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0161\n",
      "batch accuracy: 0.016097260639071465\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0159\n",
      "batch accuracy: 0.015899399295449257\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0143\n",
      "batch accuracy: 0.014310082420706749\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0190\n",
      "batch accuracy: 0.019022133201360703\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0389\n",
      "batch accuracy: 0.03885463997721672\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0184\n",
      "batch accuracy: 0.018390731886029243\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0401\n",
      "batch accuracy: 0.040132325142621994\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0286\n",
      "batch accuracy: 0.02856566198170185\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0244\n",
      "batch accuracy: 0.02439330331981182\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0149\n",
      "batch accuracy: 0.014909825287759304\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0205\n",
      "batch accuracy: 0.020468395203351974\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0289\n",
      "batch accuracy: 0.028906097635626793\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0206\n",
      "batch accuracy: 0.020566308870911598\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0223\n",
      "batch accuracy: 0.02233293652534485\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0260\n",
      "batch accuracy: 0.026015980169177055\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0266\n",
      "batch accuracy: 0.026626499369740486\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0255\n",
      "batch accuracy: 0.02550102397799492\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0246\n",
      "batch accuracy: 0.02460542507469654\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0267\n",
      "batch accuracy: 0.02673945762217045\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0400\n",
      "batch accuracy: 0.03999151661992073\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0263\n",
      "batch accuracy: 0.026343269273638725\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0248\n",
      "batch accuracy: 0.024783015251159668\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0174\n",
      "batch accuracy: 0.017375130206346512\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0188\n",
      "batch accuracy: 0.01879609003663063\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0173\n",
      "batch accuracy: 0.01734975166618824\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0132\n",
      "batch accuracy: 0.013202913105487823\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0117\n",
      "batch accuracy: 0.011699712835252285\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098\n",
      "batch accuracy: 0.009771387092769146\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085\n",
      "batch accuracy: 0.00850489642471075\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111\n",
      "batch accuracy: 0.011146028526127338\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074\n",
      "batch accuracy: 0.007391721475869417\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071\n",
      "batch accuracy: 0.007065884303301573\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005555901676416397\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008177259936928749\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004396194126456976\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.0049962145276367664\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080\n",
      "batch accuracy: 0.008001737296581268\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073\n",
      "batch accuracy: 0.00726332189515233\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.0058839586563408375\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0058\n",
      "batch accuracy: 0.0058077247813344\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004438615404069424\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072\n",
      "batch accuracy: 0.00719029363244772\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091\n",
      "batch accuracy: 0.009069272316992283\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007590101100504398\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0057\n",
      "batch accuracy: 0.005691654980182648\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0064747268334031105\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100\n",
      "batch accuracy: 0.010002861730754375\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0136\n",
      "batch accuracy: 0.013565897941589355\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007638932671397924\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0153\n",
      "batch accuracy: 0.015291707590222359\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0118\n",
      "batch accuracy: 0.011778728105127811\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0139\n",
      "batch accuracy: 0.013926574029028416\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0127\n",
      "batch accuracy: 0.012701155617833138\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070\n",
      "batch accuracy: 0.007000710349529982\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0112\n",
      "batch accuracy: 0.011201135814189911\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098\n",
      "batch accuracy: 0.009803763590753078\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0115\n",
      "batch accuracy: 0.011535773985087872\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0106\n",
      "batch accuracy: 0.010640949010848999\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091\n",
      "batch accuracy: 0.009090024046599865\n",
      "doing a bulk of  5 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0099\n",
      "batch accuracy: 0.009896055795252323\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110\n",
      "batch accuracy: 0.010955397970974445\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0133\n",
      "batch accuracy: 0.01326329167932272\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009612319059669971\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085\n",
      "batch accuracy: 0.008508368395268917\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094\n",
      "batch accuracy: 0.009365225210785866\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009622433222830296\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105\n",
      "batch accuracy: 0.010511471889913082\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008250055834650993\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008877127431333065\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106\n",
      "batch accuracy: 0.010558203794062138\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0106\n",
      "batch accuracy: 0.01062996219843626\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0122\n",
      "batch accuracy: 0.012203216552734375\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0197\n",
      "batch accuracy: 0.019735213369131088\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0203\n",
      "batch accuracy: 0.02028748393058777\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0146\n",
      "batch accuracy: 0.014602427370846272\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0118\n",
      "batch accuracy: 0.011830223724246025\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0127\n",
      "batch accuracy: 0.012737820856273174\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107\n",
      "batch accuracy: 0.010692184790968895\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0120\n",
      "batch accuracy: 0.011996516026556492\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097\n",
      "batch accuracy: 0.009680391289293766\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0128\n",
      "batch accuracy: 0.012754768133163452\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0137\n",
      "batch accuracy: 0.01369534619152546\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0149\n",
      "batch accuracy: 0.0149237597361207\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0144\n",
      "batch accuracy: 0.014410761184990406\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0152\n",
      "batch accuracy: 0.015201641246676445\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0171\n",
      "batch accuracy: 0.017127975821495056\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0250\n",
      "batch accuracy: 0.025047646835446358\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0540\n",
      "batch accuracy: 0.05403442308306694\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0936\n",
      "batch accuracy: 0.09359806776046753\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0628\n",
      "batch accuracy: 0.06282175332307816\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0393\n",
      "batch accuracy: 0.03931555524468422\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0180\n",
      "batch accuracy: 0.01796366460621357\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099\n",
      "batch accuracy: 0.009930001571774483\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0114\n",
      "batch accuracy: 0.011409416794776917\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005562334321439266\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099\n",
      "batch accuracy: 0.009906003251671791\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0140\n",
      "batch accuracy: 0.0139926727861166\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0133\n",
      "batch accuracy: 0.013273467309772968\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082\n",
      "batch accuracy: 0.00816071406006813\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005237107630819082\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005927628837525845\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067\n",
      "batch accuracy: 0.00674323970451951\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072\n",
      "batch accuracy: 0.0071714697405695915\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078\n",
      "batch accuracy: 0.007847973145544529\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084\n",
      "batch accuracy: 0.008355140686035156\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067\n",
      "batch accuracy: 0.006745409220457077\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0243\n",
      "batch accuracy: 0.024302568286657333\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0158\n",
      "batch accuracy: 0.01581680215895176\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0108\n",
      "batch accuracy: 0.010780309326946735\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078\n",
      "batch accuracy: 0.007768150418996811\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067\n",
      "batch accuracy: 0.006745986640453339\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004746663849800825\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0032478065695613623\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004320926498621702\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0125\n",
      "batch accuracy: 0.012481779791414738\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0170\n",
      "batch accuracy: 0.017024796456098557\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0389\n",
      "batch accuracy: 0.0389334075152874\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0208\n",
      "batch accuracy: 0.020771251991391182\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0162\n",
      "batch accuracy: 0.01615813374519348\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0173\n",
      "batch accuracy: 0.01728922873735428\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093\n",
      "batch accuracy: 0.009253134950995445\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099\n",
      "batch accuracy: 0.00986314658075571\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086\n",
      "batch accuracy: 0.00860479474067688\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0123\n",
      "batch accuracy: 0.012254485860466957\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111\n",
      "batch accuracy: 0.011102094314992428\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005946421530097723\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007623512763530016\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005287883337587118\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038\n",
      "batch accuracy: 0.00382443075068295\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005457893013954163\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004229731857776642\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005553732626140118\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005338174756616354\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004332082811743021\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004622442182153463\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046\n",
      "batch accuracy: 0.0046232216991484165\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067\n",
      "batch accuracy: 0.006666815839707851\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005480974446982145\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004414462950080633\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053\n",
      "batch accuracy: 0.0052526588551700115\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006823098752647638\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054\n",
      "batch accuracy: 0.005448300391435623\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005757248494774103\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0064\n",
      "batch accuracy: 0.006371662952005863\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004889252129942179\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005969083867967129\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065\n",
      "batch accuracy: 0.006452877540141344\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0064590126276016235\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073\n",
      "batch accuracy: 0.007343640085309744\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006855007726699114\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006308165844529867\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006325921975076199\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.004985529463738203\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0028194808401167393\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0036742687225341797\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0031476574949920177\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066\n",
      "batch accuracy: 0.00659642368555069\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004151359666138887\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.00626011285930872\n",
      "doing a bulk of  6 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0064\n",
      "batch accuracy: 0.00640141312032938\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0116\n",
      "batch accuracy: 0.011629856191575527\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0140\n",
      "batch accuracy: 0.014004513621330261\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0158\n",
      "batch accuracy: 0.015785343945026398\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0118\n",
      "batch accuracy: 0.011808506213128567\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0125\n",
      "batch accuracy: 0.012451541610062122\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008878873661160469\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008268939331173897\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009237779304385185\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061\n",
      "batch accuracy: 0.006131498608738184\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005984913092106581\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.0048925490118563175\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.0046244049444794655\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075\n",
      "batch accuracy: 0.0074952952563762665\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006646048743277788\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006852585356682539\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004751085769385099\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.006534024607390165\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006891615688800812\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007517033256590366\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0146\n",
      "batch accuracy: 0.014574399217963219\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006781764794141054\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005348364822566509\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100\n",
      "batch accuracy: 0.009972679428756237\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004267425742000341\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007466030307114124\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005566984415054321\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057\n",
      "batch accuracy: 0.005728244781494141\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057\n",
      "batch accuracy: 0.005677555222064257\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007511987816542387\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0127\n",
      "batch accuracy: 0.0126945273950696\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0148\n",
      "batch accuracy: 0.014777605421841145\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0226\n",
      "batch accuracy: 0.022582633420825005\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0191\n",
      "batch accuracy: 0.019138073548674583\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0141\n",
      "batch accuracy: 0.014135845936834812\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0139\n",
      "batch accuracy: 0.013882269151508808\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0122\n",
      "batch accuracy: 0.012230230495333672\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072\n",
      "batch accuracy: 0.007194059435278177\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004073346499353647\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031910405959933996\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026\n",
      "batch accuracy: 0.0026066224090754986\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.00337488716468215\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0028243393171578646\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.003193028038367629\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.0038372220005840063\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003386009018868208\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005227223504334688\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003381099784746766\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004293471109122038\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037412364035844803\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0033975576516240835\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003359420457854867\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021\n",
      "batch accuracy: 0.002111766953021288\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004098282661288977\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029948099981993437\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039\n",
      "batch accuracy: 0.003881820011883974\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037\n",
      "batch accuracy: 0.003702250774949789\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025\n",
      "batch accuracy: 0.0024611172266304493\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.002837705658748746\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032\n",
      "batch accuracy: 0.003172480734065175\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003078736597672105\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029973103664815426\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0033934847451746464\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044\n",
      "batch accuracy: 0.00442903395742178\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029944139532744884\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0032493772450834513\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0035102670080959797\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004569318611174822\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.0037903543561697006\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.003003279911354184\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005975695792585611\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026\n",
      "batch accuracy: 0.0025871170219033957\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0035743380431085825\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.00445153983309865\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003373020561411977\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041\n",
      "batch accuracy: 0.00414617033675313\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004240638110786676\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0033429081086069345\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031912324484437704\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0033309899736195803\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0035691463854163885\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004893566947430372\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004403835628181696\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0030128215439617634\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029561701230704784\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023\n",
      "batch accuracy: 0.0023049195297062397\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022\n",
      "batch accuracy: 0.0021794294007122517\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020\n",
      "batch accuracy: 0.0019731982611119747\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004642803687602282\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027\n",
      "batch accuracy: 0.002662446117028594\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0033027403987944126\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.002860381966456771\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0027850570622831583\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0031484507489949465\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0027636014856398106\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004057958256453276\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040\n",
      "batch accuracy: 0.0039593493565917015\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005104414187371731\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004674277734011412\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070\n",
      "batch accuracy: 0.006985064595937729\n",
      "doing a bulk of  7 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007618300151079893\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.0068444195203483105\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009644023142755032\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008123591542243958\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077\n",
      "batch accuracy: 0.007716049440205097\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080\n",
      "batch accuracy: 0.008030218072235584\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090\n",
      "batch accuracy: 0.009013009257614613\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005826500244438648\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005554727744311094\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005206231959164143\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005554433446377516\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057\n",
      "batch accuracy: 0.005688746925443411\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078\n",
      "batch accuracy: 0.007804921828210354\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004440267104655504\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087\n",
      "batch accuracy: 0.008664144203066826\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007577463984489441\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008087901398539543\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006800542585551739\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009220770560204983\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0115\n",
      "batch accuracy: 0.011470797471702099\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093\n",
      "batch accuracy: 0.009344230405986309\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0138\n",
      "batch accuracy: 0.013816219754517078\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0113\n",
      "batch accuracy: 0.011346904560923576\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0109\n",
      "batch accuracy: 0.010901014320552349\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0138\n",
      "batch accuracy: 0.013849956914782524\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0123\n",
      "batch accuracy: 0.012256545946002007\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071\n",
      "batch accuracy: 0.00712225865572691\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084\n",
      "batch accuracy: 0.00840460229665041\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004742170684039593\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049\n",
      "batch accuracy: 0.0049046920612454414\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089\n",
      "batch accuracy: 0.00892875250428915\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091\n",
      "batch accuracy: 0.009076465852558613\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0132\n",
      "batch accuracy: 0.013192949816584587\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0139\n",
      "batch accuracy: 0.013902745209634304\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0136\n",
      "batch accuracy: 0.01355626992881298\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0181\n",
      "batch accuracy: 0.018122076988220215\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0228\n",
      "batch accuracy: 0.022757437080144882\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0271\n",
      "batch accuracy: 0.02705843187868595\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0253\n",
      "batch accuracy: 0.02534308098256588\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0252\n",
      "batch accuracy: 0.02523208037018776\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0181\n",
      "batch accuracy: 0.01814327947795391\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0143\n",
      "batch accuracy: 0.014316009357571602\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0195\n",
      "batch accuracy: 0.019455118104815483\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0171\n",
      "batch accuracy: 0.01707804761826992\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0142\n",
      "batch accuracy: 0.014190087094902992\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0143\n",
      "batch accuracy: 0.014313682913780212\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0159\n",
      "batch accuracy: 0.015863219276070595\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0232\n",
      "batch accuracy: 0.023166021332144737\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0225\n",
      "batch accuracy: 0.022454883903265\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0169\n",
      "batch accuracy: 0.016932962462306023\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0160\n",
      "batch accuracy: 0.016010399907827377\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0186\n",
      "batch accuracy: 0.018556300550699234\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0179\n",
      "batch accuracy: 0.017947126179933548\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0183\n",
      "batch accuracy: 0.01827313005924225\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0175\n",
      "batch accuracy: 0.01754215732216835\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0186\n",
      "batch accuracy: 0.01856270246207714\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0171\n",
      "batch accuracy: 0.017051052302122116\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0138\n",
      "batch accuracy: 0.01379846129566431\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0139\n",
      "batch accuracy: 0.013887302950024605\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0120\n",
      "batch accuracy: 0.012029801495373249\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0111\n",
      "batch accuracy: 0.01105407066643238\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008265978656709194\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071\n",
      "batch accuracy: 0.007116906810551882\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007634104695171118\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070\n",
      "batch accuracy: 0.006974183022975922\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008270611055195332\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0157\n",
      "batch accuracy: 0.015682395547628403\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0112\n",
      "batch accuracy: 0.01122655626386404\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0123\n",
      "batch accuracy: 0.012333011254668236\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0133\n",
      "batch accuracy: 0.013285825029015541\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0109\n",
      "batch accuracy: 0.010936238802969456\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093\n",
      "batch accuracy: 0.009339123964309692\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091\n",
      "batch accuracy: 0.009140381589531898\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0097\n",
      "batch accuracy: 0.00974485743790865\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0110\n",
      "batch accuracy: 0.010986844077706337\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0117\n",
      "batch accuracy: 0.01169845461845398\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008058098144829273\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0136\n",
      "batch accuracy: 0.013593404553830624\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0168\n",
      "batch accuracy: 0.016817601397633553\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0176\n",
      "batch accuracy: 0.017568491399288177\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0139\n",
      "batch accuracy: 0.01391677837818861\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0122\n",
      "batch accuracy: 0.012224113568663597\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0169\n",
      "batch accuracy: 0.016915705054998398\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0112\n",
      "batch accuracy: 0.011168145574629307\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0193\n",
      "batch accuracy: 0.019287211820483208\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0188\n",
      "batch accuracy: 0.018837541341781616\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0153\n",
      "batch accuracy: 0.015280494466423988\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0205\n",
      "batch accuracy: 0.02054320089519024\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0204\n",
      "batch accuracy: 0.020430926233530045\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0224\n",
      "batch accuracy: 0.02238820306956768\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0319\n",
      "batch accuracy: 0.03186042234301567\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0155\n",
      "batch accuracy: 0.015467924065887928\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0247\n",
      "batch accuracy: 0.024671971797943115\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0153\n",
      "batch accuracy: 0.015292751602828503\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0169\n",
      "batch accuracy: 0.01688484661281109\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0227\n",
      "batch accuracy: 0.022746656090021133\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0213\n",
      "batch accuracy: 0.021282240748405457\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0202\n",
      "batch accuracy: 0.020182017236948013\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0161\n",
      "batch accuracy: 0.016138220205903053\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0231\n",
      "batch accuracy: 0.023063430562615395\n",
      "doing a bulk of  8 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0209\n",
      "batch accuracy: 0.020948152989149094\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0151\n",
      "batch accuracy: 0.015133037231862545\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0162\n",
      "batch accuracy: 0.016238639131188393\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0141\n",
      "batch accuracy: 0.014140410348773003\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0131\n",
      "batch accuracy: 0.013124964199960232\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0152\n",
      "batch accuracy: 0.01518302969634533\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100\n",
      "batch accuracy: 0.009979717433452606\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0132\n",
      "batch accuracy: 0.013248534873127937\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101\n",
      "batch accuracy: 0.010057543404400349\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0124\n",
      "batch accuracy: 0.01239641010761261\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0160\n",
      "batch accuracy: 0.015960173681378365\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0158\n",
      "batch accuracy: 0.0158491563051939\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0152\n",
      "batch accuracy: 0.015226316638290882\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0137\n",
      "batch accuracy: 0.013738438487052917\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088\n",
      "batch accuracy: 0.00880532804876566\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0113\n",
      "batch accuracy: 0.011347368359565735\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107\n",
      "batch accuracy: 0.010740652680397034\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0117\n",
      "batch accuracy: 0.011741945520043373\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094\n",
      "batch accuracy: 0.009354761801660061\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0064792088232934475\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0133\n",
      "batch accuracy: 0.013341766782104969\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0127\n",
      "batch accuracy: 0.012701590545475483\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0160\n",
      "batch accuracy: 0.016045544296503067\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0155\n",
      "batch accuracy: 0.015489870682358742\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0153\n",
      "batch accuracy: 0.015340584330260754\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0198\n",
      "batch accuracy: 0.019805820658802986\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0219\n",
      "batch accuracy: 0.021947698667645454\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0358\n",
      "batch accuracy: 0.03581820800900459\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0241\n",
      "batch accuracy: 0.02405320107936859\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0240\n",
      "batch accuracy: 0.02404666878283024\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0260\n",
      "batch accuracy: 0.025998597964644432\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0342\n",
      "batch accuracy: 0.034217510372400284\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0272\n",
      "batch accuracy: 0.027237141504883766\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0257\n",
      "batch accuracy: 0.02572954073548317\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0224\n",
      "batch accuracy: 0.022412490099668503\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0222\n",
      "batch accuracy: 0.022204454988241196\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0196\n",
      "batch accuracy: 0.019634535536170006\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0166\n",
      "batch accuracy: 0.01656920835375786\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0153\n",
      "batch accuracy: 0.015267744660377502\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0163\n",
      "batch accuracy: 0.016315696761012077\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0144\n",
      "batch accuracy: 0.014366072602570057\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0123\n",
      "batch accuracy: 0.012346329167485237\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094\n",
      "batch accuracy: 0.00944580789655447\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0112\n",
      "batch accuracy: 0.011215860955417156\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006791491527110338\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0117\n",
      "batch accuracy: 0.01165043469518423\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090\n",
      "batch accuracy: 0.008967871777713299\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008091378025710583\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076\n",
      "batch accuracy: 0.00762971444055438\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087\n",
      "batch accuracy: 0.00872092042118311\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073\n",
      "batch accuracy: 0.007309949491173029\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008090066723525524\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.00549929728731513\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006196876056492329\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052\n",
      "batch accuracy: 0.0051641324535012245\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006152554415166378\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004304856993257999\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.00489018764346838\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063\n",
      "batch accuracy: 0.00632607052102685\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040\n",
      "batch accuracy: 0.003956072498112917\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.0048265764489769936\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006775050889700651\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004798874258995056\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085\n",
      "batch accuracy: 0.008507346734404564\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105\n",
      "batch accuracy: 0.010527952574193478\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090\n",
      "batch accuracy: 0.009020914323627949\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009172344580292702\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0084\n",
      "batch accuracy: 0.008430003188550472\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093\n",
      "batch accuracy: 0.00933072715997696\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087\n",
      "batch accuracy: 0.008734817616641521\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005553926341235638\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004452981054782867\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004625286441296339\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057\n",
      "batch accuracy: 0.005739655811339617\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004219954367727041\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005535739473998547\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061\n",
      "batch accuracy: 0.006066463887691498\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005461915396153927\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004629848059266806\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0033901811111718416\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005087266210466623\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037\n",
      "batch accuracy: 0.00372810335829854\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004566121380776167\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004231104627251625\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0032264646142721176\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040\n",
      "batch accuracy: 0.00402795197442174\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.00409079110249877\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0035286799538880587\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036202811170369387\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054\n",
      "batch accuracy: 0.005384164862334728\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065\n",
      "batch accuracy: 0.00650503346696496\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0064936415292322636\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004730403423309326\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006630827207118273\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006302073132246733\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005155446473509073\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.0038064427208155394\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0052\n",
      "batch accuracy: 0.0052488078363239765\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005786300636827946\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079\n",
      "batch accuracy: 0.00785624235868454\n",
      "doing a bulk of  9 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0066\n",
      "batch accuracy: 0.0066477092914283276\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108\n",
      "batch accuracy: 0.010756827890872955\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006925612688064575\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005799376871436834\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.00428801728412509\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008056418038904667\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073\n",
      "batch accuracy: 0.007289629429578781\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061\n",
      "batch accuracy: 0.006143834907561541\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0085\n",
      "batch accuracy: 0.008542977273464203\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091\n",
      "batch accuracy: 0.009146462194621563\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088\n",
      "batch accuracy: 0.008751695044338703\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0118\n",
      "batch accuracy: 0.011806061491370201\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009578391909599304\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006788529455661774\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079\n",
      "batch accuracy: 0.00793842226266861\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071\n",
      "batch accuracy: 0.007128868252038956\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070\n",
      "batch accuracy: 0.006952886935323477\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009204313158988953\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083\n",
      "batch accuracy: 0.00831389706581831\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0105\n",
      "batch accuracy: 0.010502277873456478\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0149\n",
      "batch accuracy: 0.01489564124494791\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0150\n",
      "batch accuracy: 0.015043122693896294\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0149\n",
      "batch accuracy: 0.014904565177857876\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0129\n",
      "batch accuracy: 0.012872428633272648\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0117\n",
      "batch accuracy: 0.011748718097805977\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101\n",
      "batch accuracy: 0.010148557834327221\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072\n",
      "batch accuracy: 0.007220820989459753\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068\n",
      "batch accuracy: 0.0067679849453270435\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099\n",
      "batch accuracy: 0.009884925559163094\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098\n",
      "batch accuracy: 0.00984621699899435\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087\n",
      "batch accuracy: 0.008739127777516842\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088\n",
      "batch accuracy: 0.008800189010798931\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009613155387341976\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0127\n",
      "batch accuracy: 0.012650877237319946\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0130\n",
      "batch accuracy: 0.013042569160461426\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0142\n",
      "batch accuracy: 0.014171893708407879\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0119\n",
      "batch accuracy: 0.011946792714297771\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106\n",
      "batch accuracy: 0.01062887441366911\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087\n",
      "batch accuracy: 0.008729674853384495\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070\n",
      "batch accuracy: 0.007035383488982916\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005571301560848951\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0065116737969219685\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006248605903238058\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007500551175326109\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060\n",
      "batch accuracy: 0.006023790687322617\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063\n",
      "batch accuracy: 0.0063064065761864185\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006892267148941755\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005972307175397873\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0064\n",
      "batch accuracy: 0.006445687264204025\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004939583595842123\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005174168385565281\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057\n",
      "batch accuracy: 0.00570646720007062\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046\n",
      "batch accuracy: 0.0045702955685555935\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004172735381871462\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006254727486521006\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0032798952888697386\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.0050276657566428185\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.003822786035016179\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040\n",
      "batch accuracy: 0.004013328813016415\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037068307865411043\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027\n",
      "batch accuracy: 0.0027334645856171846\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024\n",
      "batch accuracy: 0.0023810637649148703\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025\n",
      "batch accuracy: 0.0024792407639324665\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020\n",
      "batch accuracy: 0.0020281337201595306\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031990092247724533\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040\n",
      "batch accuracy: 0.003990778233855963\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037139509804546833\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005559248384088278\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.002816764172166586\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063\n",
      "batch accuracy: 0.00625996058806777\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030\n",
      "batch accuracy: 0.003000508528202772\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009185641072690487\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073\n",
      "batch accuracy: 0.0073029338382184505\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004616514779627323\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0084\n",
      "batch accuracy: 0.008365041576325893\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056\n",
      "batch accuracy: 0.0055542998015880585\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005103854928165674\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004117828328162432\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.00444300239905715\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0030520115979015827\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0032350902911275625\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.003502670442685485\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004161987919360399\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039\n",
      "batch accuracy: 0.0039178249426186085\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054\n",
      "batch accuracy: 0.005446239374577999\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067\n",
      "batch accuracy: 0.006683085113763809\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004612579941749573\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004303880035877228\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004570988472551107\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065\n",
      "batch accuracy: 0.006513466127216816\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006844806484878063\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090\n",
      "batch accuracy: 0.009038425050675869\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008186674676835537\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0059\n",
      "batch accuracy: 0.00585642596706748\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007505260407924652\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004105894826352596\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040\n",
      "batch accuracy: 0.004049972165375948\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0064735449850559235\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105\n",
      "batch accuracy: 0.010477954521775246\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102\n",
      "batch accuracy: 0.010222168639302254\n",
      "doing a bulk of  10 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0064614214934408665\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006876130122691393\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024\n",
      "batch accuracy: 0.0024318236391991377\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029925263952463865\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004913111682981253\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004481646232306957\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008187715895473957\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008906453847885132\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098\n",
      "batch accuracy: 0.009782501496374607\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0108\n",
      "batch accuracy: 0.010750130750238895\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "batch accuracy: 0.0092081343755126\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105\n",
      "batch accuracy: 0.010525716468691826\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008183986879885197\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097\n",
      "batch accuracy: 0.009719864465296268\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008080639876425266\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006623882334679365\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005333822686225176\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004419495817273855\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009647848084568977\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086\n",
      "batch accuracy: 0.008570369333028793\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004694006405770779\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090\n",
      "batch accuracy: 0.008951934054493904\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004677396267652512\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004866431467235088\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088\n",
      "batch accuracy: 0.008793392218649387\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008154116570949554\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006818296853452921\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009574507363140583\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005900692194700241\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006609943695366383\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005205217283219099\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065\n",
      "batch accuracy: 0.006505620200186968\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004283114802092314\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039\n",
      "batch accuracy: 0.0038785964716225863\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0030563529580831528\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036130256485193968\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005186550319194794\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070\n",
      "batch accuracy: 0.006969529204070568\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.0059917643666267395\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065\n",
      "batch accuracy: 0.0065290131606161594\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.00461552944034338\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004780707415193319\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074\n",
      "batch accuracy: 0.007382178213447332\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073\n",
      "batch accuracy: 0.007270617876201868\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072\n",
      "batch accuracy: 0.0072262403555214405\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074\n",
      "batch accuracy: 0.007391866762191057\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093\n",
      "batch accuracy: 0.009332569316029549\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079\n",
      "batch accuracy: 0.007923411205410957\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005779928993433714\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080\n",
      "batch accuracy: 0.0080116493627429\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071\n",
      "batch accuracy: 0.007128636818379164\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.00499547878280282\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005641281139105558\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004753754939883947\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062\n",
      "batch accuracy: 0.0062191360630095005\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.00502127455547452\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005486250855028629\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004551953636109829\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005227335263043642\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093\n",
      "batch accuracy: 0.009347288869321346\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093\n",
      "batch accuracy: 0.009348941966891289\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080\n",
      "batch accuracy: 0.007974534295499325\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091\n",
      "batch accuracy: 0.00914008915424347\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005839858204126358\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080\n",
      "batch accuracy: 0.007993665523827076\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.0050370232202112675\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0064\n",
      "batch accuracy: 0.006372805684804916\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.003559078322723508\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004562475252896547\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037\n",
      "batch accuracy: 0.003748751012608409\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0030976030975580215\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047\n",
      "batch accuracy: 0.0047207968309521675\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0030438248068094254\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.00297990208491683\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003410309785977006\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.0028999869246035814\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0035196777898818254\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.003492293879389763\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003098906949162483\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004815924912691116\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0032785411458462477\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033\n",
      "batch accuracy: 0.003333143889904022\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.0038106441497802734\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0027743566315621138\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003111953614279628\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004502276424318552\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026\n",
      "batch accuracy: 0.002633359283208847\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0032551593612879515\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003060731803998351\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0028028010856360197\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024\n",
      "batch accuracy: 0.0023863522801548243\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023\n",
      "batch accuracy: 0.002325698733329773\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018\n",
      "batch accuracy: 0.0017893729964271188\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037262937985360622\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020\n",
      "batch accuracy: 0.002037032274529338\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017\n",
      "batch accuracy: 0.001714113401249051\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026\n",
      "batch accuracy: 0.0025925743393599987\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039\n",
      "batch accuracy: 0.003924755845218897\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.00484486622735858\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044\n",
      "batch accuracy: 0.0043889605440199375\n",
      "doing a bulk of  11 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0050\n",
      "batch accuracy: 0.004982031416147947\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004651071969419718\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.0029119413811713457\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038\n",
      "batch accuracy: 0.0038449594285339117\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004575296770781279\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005453514400869608\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004198411479592323\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004787961952388287\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.002760532544925809\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036043599247932434\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.0048981099389493465\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008251535706222057\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090\n",
      "batch accuracy: 0.009005522355437279\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0260\n",
      "batch accuracy: 0.025955557823181152\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0260\n",
      "batch accuracy: 0.025950098410248756\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0295\n",
      "batch accuracy: 0.029488293454051018\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0383\n",
      "batch accuracy: 0.03829608112573624\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0361\n",
      "batch accuracy: 0.03613371402025223\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0345\n",
      "batch accuracy: 0.03453758358955383\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0317\n",
      "batch accuracy: 0.03170454502105713\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0238\n",
      "batch accuracy: 0.023785021156072617\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0185\n",
      "batch accuracy: 0.01851104572415352\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0198\n",
      "batch accuracy: 0.019825467839837074\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0172\n",
      "batch accuracy: 0.01721285842359066\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0190\n",
      "batch accuracy: 0.019028540700674057\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0167\n",
      "batch accuracy: 0.016691623255610466\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0233\n",
      "batch accuracy: 0.02326042391359806\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0191\n",
      "batch accuracy: 0.019091548398137093\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0179\n",
      "batch accuracy: 0.01792880892753601\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0117\n",
      "batch accuracy: 0.011662415228784084\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0129\n",
      "batch accuracy: 0.012890435755252838\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0134\n",
      "batch accuracy: 0.013369517400860786\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0121\n",
      "batch accuracy: 0.012071638368070126\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106\n",
      "batch accuracy: 0.010605067014694214\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095\n",
      "batch accuracy: 0.00948464684188366\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009231112897396088\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095\n",
      "batch accuracy: 0.00952459592372179\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101\n",
      "batch accuracy: 0.010105618275702\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095\n",
      "batch accuracy: 0.009523465298116207\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0146\n",
      "batch accuracy: 0.014550098218023777\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0123\n",
      "batch accuracy: 0.012293168343603611\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0125\n",
      "batch accuracy: 0.012524832971394062\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0131\n",
      "batch accuracy: 0.013052421621978283\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0117\n",
      "batch accuracy: 0.011650570668280125\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0147\n",
      "batch accuracy: 0.014661796391010284\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0178\n",
      "batch accuracy: 0.017806854099035263\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0181\n",
      "batch accuracy: 0.01808142103254795\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0226\n",
      "batch accuracy: 0.022565754130482674\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0207\n",
      "batch accuracy: 0.02071128413081169\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0195\n",
      "batch accuracy: 0.019512880593538284\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0253\n",
      "batch accuracy: 0.025310009717941284\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0302\n",
      "batch accuracy: 0.030185673385858536\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0162\n",
      "batch accuracy: 0.01617082767188549\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0135\n",
      "batch accuracy: 0.013517203740775585\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0169\n",
      "batch accuracy: 0.01691209338605404\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0190\n",
      "batch accuracy: 0.01902875304222107\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0267\n",
      "batch accuracy: 0.026710424572229385\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0192\n",
      "batch accuracy: 0.019177565351128578\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0157\n",
      "batch accuracy: 0.01570889540016651\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0220\n",
      "batch accuracy: 0.022027036175131798\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090\n",
      "batch accuracy: 0.008988365530967712\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0132\n",
      "batch accuracy: 0.01315754558891058\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0211\n",
      "batch accuracy: 0.021122613921761513\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0159\n",
      "batch accuracy: 0.015933748334646225\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0207\n",
      "batch accuracy: 0.020685898140072823\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0148\n",
      "batch accuracy: 0.014833902008831501\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0168\n",
      "batch accuracy: 0.01679375022649765\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0144\n",
      "batch accuracy: 0.014407997019588947\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0160\n",
      "batch accuracy: 0.016041379421949387\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0145\n",
      "batch accuracy: 0.014530515298247337\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0120\n",
      "batch accuracy: 0.011963190510869026\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095\n",
      "batch accuracy: 0.009496047161519527\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091\n",
      "batch accuracy: 0.009129424579441547\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078\n",
      "batch accuracy: 0.00780823128297925\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067\n",
      "batch accuracy: 0.006691779475659132\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090\n",
      "batch accuracy: 0.008996786549687386\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0146\n",
      "batch accuracy: 0.014601511880755424\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007514219265431166\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069\n",
      "batch accuracy: 0.0068876780569553375\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006567326840013266\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070\n",
      "batch accuracy: 0.007011710200458765\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081\n",
      "batch accuracy: 0.008105517365038395\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0137\n",
      "batch accuracy: 0.013679368421435356\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0112\n",
      "batch accuracy: 0.011227444745600224\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111\n",
      "batch accuracy: 0.011108704842627048\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0122\n",
      "batch accuracy: 0.012184619903564453\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007509533315896988\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099\n",
      "batch accuracy: 0.009904609061777592\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008916816674172878\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006612645927816629\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097\n",
      "batch accuracy: 0.009742972441017628\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008152562193572521\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008868671022355556\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0079\n",
      "batch accuracy: 0.007887035608291626\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009601413272321224\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0120\n",
      "batch accuracy: 0.011955128982663155\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008179500699043274\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111\n",
      "batch accuracy: 0.011061104945838451\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0132\n",
      "batch accuracy: 0.013167647644877434\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0109\n",
      "batch accuracy: 0.010948761366307735\n",
      "doing a bulk of  12 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008874011225998402\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071\n",
      "batch accuracy: 0.007096495013684034\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006574180908501148\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005332592874765396\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004185630939900875\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006627322174608707\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0064\n",
      "batch accuracy: 0.006418255157768726\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005532138515263796\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005618749652057886\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.0067581795156002045\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.00662348885089159\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.0044947960413992405\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004912158939987421\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008280434645712376\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006243772339075804\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004825321026146412\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005923744291067123\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042\n",
      "batch accuracy: 0.0042398422956466675\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004881597124040127\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.00458288099616766\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0051\n",
      "batch accuracy: 0.00508255185559392\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005967447068542242\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039\n",
      "batch accuracy: 0.003850097069516778\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.0059493957087397575\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005121587309986353\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040\n",
      "batch accuracy: 0.00395849347114563\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.0053222752176225185\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004699363838881254\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005200058687478304\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067\n",
      "batch accuracy: 0.006687545217573643\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068\n",
      "batch accuracy: 0.006844348274171352\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074\n",
      "batch accuracy: 0.007414606399834156\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005941904149949551\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005106286145746708\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076\n",
      "batch accuracy: 0.007573882583528757\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074\n",
      "batch accuracy: 0.007357005029916763\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005252469331026077\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0127\n",
      "batch accuracy: 0.012736531905829906\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060\n",
      "batch accuracy: 0.0059724715538322926\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072\n",
      "batch accuracy: 0.0072059486992657185\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052\n",
      "batch accuracy: 0.005212486255913973\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072\n",
      "batch accuracy: 0.007208800408989191\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073\n",
      "batch accuracy: 0.007294345647096634\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.006514515727758408\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004765681456774473\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005854904185980558\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077\n",
      "batch accuracy: 0.0076619768515229225\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006564619485288858\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073\n",
      "batch accuracy: 0.0072740777395665646\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072\n",
      "batch accuracy: 0.007248708046972752\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "batch accuracy: 0.009210964664816856\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080\n",
      "batch accuracy: 0.008043505251407623\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083\n",
      "batch accuracy: 0.008317138068377972\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070\n",
      "batch accuracy: 0.006994167808443308\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080\n",
      "batch accuracy: 0.007953021675348282\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069\n",
      "batch accuracy: 0.00694955512881279\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089\n",
      "batch accuracy: 0.008884584531188011\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073\n",
      "batch accuracy: 0.007280379068106413\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072\n",
      "batch accuracy: 0.007218680344521999\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069\n",
      "batch accuracy: 0.006920204497873783\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061\n",
      "batch accuracy: 0.006121077574789524\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008169506676495075\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005953994579613209\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096\n",
      "batch accuracy: 0.009596412070095539\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.00645390385761857\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.00496531929820776\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071\n",
      "batch accuracy: 0.007126989308744669\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006562189664691687\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0058\n",
      "batch accuracy: 0.005755354184657335\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.0052719563245773315\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075\n",
      "batch accuracy: 0.00746366661041975\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086\n",
      "batch accuracy: 0.008625253103673458\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085\n",
      "batch accuracy: 0.008490560576319695\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0058\n",
      "batch accuracy: 0.0057713426649570465\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005269445478916168\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004258379805833101\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.00448406208306551\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004838073160499334\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040\n",
      "batch accuracy: 0.003970567602664232\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005565953906625509\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006262071430683136\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004922759719192982\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005497022531926632\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049\n",
      "batch accuracy: 0.0048902141861617565\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005510397255420685\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003376581473276019\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036025159060955048\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.003800690174102783\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027\n",
      "batch accuracy: 0.002745155245065689\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031966606620699167\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005488971713930368\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097\n",
      "batch accuracy: 0.009706439450383186\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006208698730915785\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005894051399081945\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0064\n",
      "batch accuracy: 0.00641460670158267\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004462704993784428\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004881170112639666\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004388731438666582\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003403185633942485\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006604313384741545\n",
      "doing a bulk of  13 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0087\n",
      "batch accuracy: 0.00873108021914959\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005991861689835787\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046\n",
      "batch accuracy: 0.0046374984085559845\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054\n",
      "batch accuracy: 0.005413332022726536\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065\n",
      "batch accuracy: 0.006497477646917105\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083\n",
      "batch accuracy: 0.00829407013952732\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049\n",
      "batch accuracy: 0.004882908891886473\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005953827407211065\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029623040463775396\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028\n",
      "batch accuracy: 0.00280018406920135\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030\n",
      "batch accuracy: 0.002990931272506714\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0031064567156136036\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037054293788969517\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023\n",
      "batch accuracy: 0.0023453086614608765\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004370526410639286\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022\n",
      "batch accuracy: 0.0022357020061463118\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0029\n",
      "batch accuracy: 0.002858672058209777\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0033639497123658657\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004710159730166197\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.004973905626684427\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082\n",
      "batch accuracy: 0.008238567970693111\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004702296108007431\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098\n",
      "batch accuracy: 0.009751511737704277\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045\n",
      "batch accuracy: 0.0044511849991977215\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005461185239255428\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005627396050840616\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.003325490280985832\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044\n",
      "batch accuracy: 0.004429319407790899\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027\n",
      "batch accuracy: 0.002716005314141512\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0034072462003678083\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041\n",
      "batch accuracy: 0.0041282218880951405\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041\n",
      "batch accuracy: 0.0041332240216434\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037244658451527357\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038\n",
      "batch accuracy: 0.003766014939174056\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040\n",
      "batch accuracy: 0.003970217425376177\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.002935839118435979\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006278787273913622\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032\n",
      "batch accuracy: 0.003241267055273056\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031580638606101274\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005304995458573103\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005097410641610622\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005873552523553371\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0033816799987107515\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026\n",
      "batch accuracy: 0.0026473794132471085\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018\n",
      "batch accuracy: 0.0017729403916746378\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015\n",
      "batch accuracy: 0.0015489541692659259\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.003162351669743657\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024\n",
      "batch accuracy: 0.002409733599051833\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030\n",
      "batch accuracy: 0.002953581279143691\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029\n",
      "batch accuracy: 0.0028668383602052927\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031872871331870556\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023\n",
      "batch accuracy: 0.0022892621345818043\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025\n",
      "batch accuracy: 0.002501249313354492\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030\n",
      "batch accuracy: 0.003047702368348837\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.003312691580504179\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034\n",
      "batch accuracy: 0.0034153214655816555\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036\n",
      "batch accuracy: 0.003568322164937854\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043\n",
      "batch accuracy: 0.0042699105106294155\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0028247602749615908\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042\n",
      "batch accuracy: 0.004202627576887608\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029\n",
      "batch accuracy: 0.0028528370894491673\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0035924960393458605\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057\n",
      "batch accuracy: 0.005708364304155111\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0030543494503945112\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004257327411323786\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.00310748303309083\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003056867280974984\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025\n",
      "batch accuracy: 0.0024964052718132734\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.002890712348744273\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036\n",
      "batch accuracy: 0.003573236521333456\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.00445284228771925\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039\n",
      "batch accuracy: 0.0038733116816729307\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.00450780987739563\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.003468342125415802\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0034960650373250246\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027\n",
      "batch accuracy: 0.002722602803260088\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029634356033056974\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029\n",
      "batch accuracy: 0.0028869493398815393\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027\n",
      "batch accuracy: 0.0027158516459167004\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021\n",
      "batch accuracy: 0.0021170969121158123\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.003180642146617174\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027\n",
      "batch accuracy: 0.002682792255654931\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023\n",
      "batch accuracy: 0.0023173349909484386\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030\n",
      "batch accuracy: 0.003045234829187393\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.00318850832991302\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0027611106634140015\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0035587709862738848\n",
      "doing a batch of  87 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.00412722397595644\n",
      "doing a batch of  88 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0031152835581451654\n",
      "doing a batch of  89 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0036555721890181303\n",
      "doing a batch of  90 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0035477837081998587\n",
      "doing a batch of  91 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0035107338335365057\n",
      "doing a batch of  92 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0030260232742875814\n",
      "doing a batch of  93 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.002916276454925537\n",
      "doing a batch of  94 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038\n",
      "batch accuracy: 0.003803263185545802\n",
      "doing a batch of  95 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.0031342562288045883\n",
      "doing a batch of  96 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027\n",
      "batch accuracy: 0.0027417284436523914\n",
      "doing a batch of  97 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032\n",
      "batch accuracy: 0.003157407511025667\n",
      "doing a batch of  98 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018\n",
      "batch accuracy: 0.0018106134375557303\n",
      "doing a batch of  99 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038\n",
      "batch accuracy: 0.0038391451817005873\n",
      "doing a bulk of  14 / 32\n",
      "getting a bluk...start \n",
      "getting a bluk...done \n",
      "getting a batch\n",
      "images per batch 14\n",
      "Number of batches 100\n",
      "doing a batch of  0 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0070\n",
      "batch accuracy: 0.00704612210392952\n",
      "doing a batch of  1 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.0028950346168130636\n",
      "doing a batch of  2 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061\n",
      "batch accuracy: 0.006064585410058498\n",
      "doing a batch of  3 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004537150263786316\n",
      "doing a batch of  4 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0079\n",
      "batch accuracy: 0.00790093932300806\n",
      "doing a batch of  5 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0064\n",
      "batch accuracy: 0.006416599731892347\n",
      "doing a batch of  6 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006180299911648035\n",
      "doing a batch of  7 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006620466709136963\n",
      "doing a batch of  8 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0030382403638213873\n",
      "doing a batch of  9 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026\n",
      "batch accuracy: 0.0025618497747927904\n",
      "doing a batch of  10 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035\n",
      "batch accuracy: 0.0034700394608080387\n",
      "doing a batch of  11 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.00328482361510396\n",
      "doing a batch of  12 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0043\n",
      "batch accuracy: 0.00434598745778203\n",
      "doing a batch of  13 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004726284649223089\n",
      "doing a batch of  14 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077\n",
      "batch accuracy: 0.007715895306318998\n",
      "doing a batch of  15 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085\n",
      "batch accuracy: 0.00847665499895811\n",
      "doing a batch of  16 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075\n",
      "batch accuracy: 0.007516093086451292\n",
      "doing a batch of  17 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070\n",
      "batch accuracy: 0.007006059866398573\n",
      "doing a batch of  18 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054\n",
      "batch accuracy: 0.005360003560781479\n",
      "doing a batch of  19 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004452363587915897\n",
      "doing a batch of  20 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032\n",
      "batch accuracy: 0.0031889535021036863\n",
      "doing a batch of  21 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003125093411654234\n",
      "doing a batch of  22 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027\n",
      "batch accuracy: 0.0026707001961767673\n",
      "doing a batch of  23 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026\n",
      "batch accuracy: 0.0025508857797831297\n",
      "doing a batch of  24 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048\n",
      "batch accuracy: 0.004754461348056793\n",
      "doing a batch of  25 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004079663194715977\n",
      "doing a batch of  26 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004105014726519585\n",
      "doing a batch of  27 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041\n",
      "batch accuracy: 0.004083720035851002\n",
      "doing a batch of  28 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004716702736914158\n",
      "doing a batch of  29 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0035930736921727657\n",
      "doing a batch of  30 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030\n",
      "batch accuracy: 0.002955837408080697\n",
      "doing a batch of  31 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0033468452747911215\n",
      "doing a batch of  32 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
      "batch accuracy: 0.005256677512079477\n",
      "doing a batch of  33 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020\n",
      "batch accuracy: 0.0020123429130762815\n",
      "doing a batch of  34 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030\n",
      "batch accuracy: 0.0029760461766272783\n",
      "doing a batch of  35 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.003276888746768236\n",
      "doing a batch of  36 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036469909828156233\n",
      "doing a batch of  37 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0035615158267319202\n",
      "doing a batch of  38 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006336841266602278\n",
      "doing a batch of  39 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036293293815106153\n",
      "doing a batch of  40 / 100\n",
      "Training start for a batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034\n",
      "batch accuracy: 0.003440575208514929\n",
      "doing a batch of  41 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056\n",
      "batch accuracy: 0.005620626267045736\n",
      "doing a batch of  42 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025\n",
      "batch accuracy: 0.002463091630488634\n",
      "doing a batch of  43 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0198\n",
      "batch accuracy: 0.019845906645059586\n",
      "doing a batch of  44 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0194\n",
      "batch accuracy: 0.019362905994057655\n",
      "doing a batch of  45 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0171\n",
      "batch accuracy: 0.017126720398664474\n",
      "doing a batch of  46 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055\n",
      "batch accuracy: 0.005512444768100977\n",
      "doing a batch of  47 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005959188099950552\n",
      "doing a batch of  48 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0051\n",
      "batch accuracy: 0.005143396090716124\n",
      "doing a batch of  49 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005956538021564484\n",
      "doing a batch of  50 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070\n",
      "batch accuracy: 0.006997755263000727\n",
      "doing a batch of  51 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.0062563130632042885\n",
      "doing a batch of  52 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063\n",
      "batch accuracy: 0.006297229789197445\n",
      "doing a batch of  53 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100\n",
      "batch accuracy: 0.009971541352570057\n",
      "doing a batch of  54 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004287017975002527\n",
      "doing a batch of  55 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.00463835196569562\n",
      "doing a batch of  56 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036\n",
      "batch accuracy: 0.0036274546291679144\n",
      "doing a batch of  57 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033\n",
      "batch accuracy: 0.0033407227601855993\n",
      "doing a batch of  58 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025\n",
      "batch accuracy: 0.002490719547495246\n",
      "doing a batch of  59 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005962445866316557\n",
      "doing a batch of  60 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038\n",
      "batch accuracy: 0.003758240956813097\n",
      "doing a batch of  61 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033\n",
      "batch accuracy: 0.003250697860494256\n",
      "doing a batch of  62 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025\n",
      "batch accuracy: 0.0024647729005664587\n",
      "doing a batch of  63 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040\n",
      "batch accuracy: 0.003974108025431633\n",
      "doing a batch of  64 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037\n",
      "batch accuracy: 0.0037447798531502485\n",
      "doing a batch of  65 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045\n",
      "batch accuracy: 0.004514828324317932\n",
      "doing a batch of  66 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031\n",
      "batch accuracy: 0.003103442955762148\n",
      "doing a batch of  67 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042\n",
      "batch accuracy: 0.0042252084240317345\n",
      "doing a batch of  68 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027\n",
      "batch accuracy: 0.0026500276289880276\n",
      "doing a batch of  69 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021\n",
      "batch accuracy: 0.002099674427881837\n",
      "doing a batch of  70 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018\n",
      "batch accuracy: 0.001805070205591619\n",
      "doing a batch of  71 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020\n",
      "batch accuracy: 0.0020225406624376774\n",
      "doing a batch of  72 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019\n",
      "batch accuracy: 0.0018749962328001857\n",
      "doing a batch of  73 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029\n",
      "batch accuracy: 0.002945354674011469\n",
      "doing a batch of  74 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028\n",
      "batch accuracy: 0.0027606715448200703\n",
      "doing a batch of  75 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047\n",
      "batch accuracy: 0.004691421519964933\n",
      "doing a batch of  76 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046\n",
      "batch accuracy: 0.004556346219033003\n",
      "doing a batch of  77 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043\n",
      "batch accuracy: 0.004286538809537888\n",
      "doing a batch of  78 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061\n",
      "batch accuracy: 0.006063974462449551\n",
      "doing a batch of  79 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040\n",
      "batch accuracy: 0.0040038698352873325\n",
      "doing a batch of  80 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0062\n",
      "batch accuracy: 0.006181982345879078\n",
      "doing a batch of  81 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066\n",
      "batch accuracy: 0.006600871216505766\n",
      "doing a batch of  82 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059\n",
      "batch accuracy: 0.005919128190726042\n",
      "doing a batch of  83 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071\n",
      "batch accuracy: 0.0071368953213095665\n",
      "doing a batch of  84 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050\n",
      "batch accuracy: 0.004962338600307703\n",
      "doing a batch of  85 / 100\n",
      "Training start for a batch\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060\n",
      "batch accuracy: 0.005971846636384726\n",
      "doing a batch of  86 / 100\n",
      "Training start for a batch\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "if restart == \"yes\":\n",
    "    print(\"restarting from era, epoch #\", restart_era, restart_epoch)\n",
    "    if restart_epoch != 0:\n",
    "        load_model(model_name + '.era_' + str(restart_era).zfill(3) + '.epoch_'+ str(restart_epoch).zfill(3) + '.h5')\n",
    "\n",
    "for era in range(restart_era, eras):\n",
    "    print(\"*\" * 50)\n",
    "    print(era, \"/\", era, \" ERAS\")\n",
    "    for epoch in range(restart_epoch, epochs):\n",
    "        print(\"=\" * 50)\n",
    "        print(epoch, \"/\", epochs, \" EPOCHS\")\n",
    "        acc = []\n",
    "\n",
    "        for X_train_bulk, Y_train_bulk in get_bulk(X_train, Y_train, images_per_bulk):\n",
    "            for X_batch, Y_batch in get_batch(X_train_bulk, Y_train_bulk, images_per_batch):\n",
    "                print('Training start for a batch')\n",
    "                # normalize data\n",
    "                X_batch = X_batch.astype('float32')\n",
    "                X_batch /= 255\n",
    "                Y_batch = Y_batch.astype('float32')\n",
    "                Y_batch /= 255\n",
    "                model.train_on_batch(X_batch, Y_batch)\n",
    "                score = model.evaluate(X_batch, Y_batch)\n",
    "                print(\"batch accuracy:\", score)\n",
    "                acc.append(score)#\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "        print(\"Train accuracy (mean)\", np.mean(acc))\n",
    "        print(\"Train accuracy (max)\", np.max(acc))\n",
    "        with open(model_name + '.era_' + str(era).zfill(3) + '.epoch_'+ str(epoch).zfill(3) + '.txt', mode='w') as f:\n",
    "            print(\"era: \", era, \" epoch: \", epoch, \" Train accuracy (mean): \", np.mean(acc), \" Train accuracy (max): \", np.max(acc), file=f)\n",
    "        model.save(model_name + '.era_' + str(era).zfill(3) + '.epoch_'+ str(epoch).zfill(3) + '.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
